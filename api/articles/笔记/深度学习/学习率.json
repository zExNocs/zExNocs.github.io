{"title":"深度学习-学习率","uid":"88524df85638f6b23deb5b7d601d5559","slug":"笔记/深度学习/学习率","date":"2025-12-26T01:00:25.000Z","updated":"2025-12-26T03:39:06.985Z","comments":true,"path":"api/articles/笔记/深度学习/学习率.json","keywords":null,"cover":"img/post/笔记/深度学习/学习率/cover.jpg","content":"<p><a href=\"%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%88%AA\">&lt;返回深度学习导航</a></p>\n<hr />\n<h1 id=\"一-学习率\"><a class=\"markdownIt-Anchor\" href=\"#一-学习率\"></a> 一. 学习率</h1>\n<p>学习率(Learning Rate, LR)是每次迭代权值更新的步长。不存在唯一完美的学习率，不同模型都需调整。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">情况</th>\n<th style=\"text-align:center\">结果</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">非常大</td>\n<td style=\"text-align:center\">loss 爆炸</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">偏大</td>\n<td style=\"text-align:center\">震荡，不易收敛</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">偏小</td>\n<td style=\"text-align:center\">收敛慢</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">快速下降且稳定</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"二-学习率调度\"><a class=\"markdownIt-Anchor\" href=\"#二-学习率调度\"></a> 二. 学习率调度</h1>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">时期</th>\n<th style=\"text-align:center\">说明</th>\n<th style=\"text-align:center\">调整</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">早期</td>\n<td style=\"text-align:center\">希望快速下降 loss</td>\n<td style=\"text-align:center\">高学习率</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">后期</td>\n<td style=\"text-align:center\">更精细地调整</td>\n<td style=\"text-align:center\">低学习率</td>\n</tr>\n</tbody>\n</table>\n<p>因此需要一个随 epoch 逐渐减少的学习率，叫做学习率衰减（Learning Rate Decay）。这个过程叫做学习率调度(Learning Rate Schedule)。</p>\n<p>以下假设</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></td>\n<td>当前 epoch</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span></span></td>\n<td>总 epoch</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>η</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\eta_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></td>\n<td>初始输入学习率</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>η</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\eta_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></td>\n<td>在 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span> 下的学习率</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"1-阶梯衰减\"><a class=\"markdownIt-Anchor\" href=\"#1-阶梯衰减\"></a> 1. 阶梯衰减</h2>\n<p>阶梯衰减(Step Decay)是在固定的 epoch 步长 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">a</span></span></span></span> 让学习率降低某一个倍数 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi><mo>∈</mo><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\beta \\in (0, 1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span></p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>η</mi><mi>t</mi></msub><mo>=</mo><msup><mi>β</mi><mrow><mo>∣</mo><mfrac><mi>t</mi><mi>a</mi></mfrac><mo>∣</mo></mrow></msup><msub><mi>η</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\eta_t = \\beta^{\\mid\\frac{t}{a}\\mid} \\eta_0\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.18378em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.98934em;\"><span style=\"top:-3.4130000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">∣</span><span class=\"mord mtight\"><span class=\"mopen nulldelimiter sizing reset-size3 size6\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8233428571428572em;\"><span style=\"top:-2.656em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span></span><span style=\"top:-3.2255000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line mtight\" style=\"border-bottom-width:0.049em;\"></span></span><span style=\"top:-3.384em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.344em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter sizing reset-size3 size6\"></span></span><span class=\"mrel mtight\">∣</span></span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>例如 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi><mo>=</mo><mn>0.1</mn><mo separator=\"true\">,</mo><mi>a</mi><mo>=</mo><mn>30</mn></mrow><annotation encoding=\"application/x-tex\">\\beta = 0.1, a = 30</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8388800000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\">0</span></span></span></span>。</p>\n<p>特点：</p>\n<ul>\n<li>简单粗暴</li>\n<li>适合 CNN、ResNet 这种稳定模型</li>\n<li>梯度下降图中会看到明显的台阶状下降</li>\n</ul>\n<h2 id=\"2-余弦衰减\"><a class=\"markdownIt-Anchor\" href=\"#2-余弦衰减\"></a> 2. 余弦衰减</h2>\n<p>余弦衰减 (Cosine Decay)：</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>η</mi><mi>t</mi></msub><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mi>η</mi><mn>0</mn></msub><mo stretchy=\"false\">(</mo><mn>1</mn><mo>+</mo><mi>cos</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mfrac><mrow><mi>t</mi><mi>π</mi></mrow><mi>T</mi></mfrac><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\eta_t = \\frac{1}{2}\\eta_0 (1 + \\cos(\\frac{t\\pi}{T}))\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.00744em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.9780799999999998em;vertical-align:-0.686em;\"></span><span class=\"mop\">cos</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.29208em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>特点：</p>\n<ul>\n<li>平滑衰减，不会突然掉太多</li>\n<li>训练后期学习率很小但不为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span></li>\n<li>常与 warmup 一起使用</li>\n<li>适合一般深度学习模型</li>\n</ul>\n<h2 id=\"3-线性衰减\"><a class=\"markdownIt-Anchor\" href=\"#3-线性衰减\"></a> 3. 线性衰减</h2>\n<p>线性衰减(Linear Decay)：</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>η</mi><mi>t</mi></msub><mo>=</mo><msub><mi>η</mi><mn>0</mn></msub><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>t</mi><mi>T</mi></mfrac><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\eta_t = \\eta_0(1 - \\frac{t}{T})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.9780799999999998em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.29208em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<ul>\n<li>常用于 NLP 模型 (例如 BERT)</li>\n</ul>\n<h2 id=\"4-逆平方根衰减\"><a class=\"markdownIt-Anchor\" href=\"#4-逆平方根衰减\"></a> 4. 逆平方根衰减</h2>\n<p>逆平方根衰减(Inverse Square Root Decay):</p>\n<p class='katex-block'><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>η</mi><mi>t</mi></msub><mo>=</mo><mfrac><msub><mi>η</mi><mn>0</mn></msub><msqrt><mi>t</mi></msqrt></mfrac></mrow><annotation encoding=\"application/x-tex\">\\eta_t = \\frac{\\eta_0}{\\sqrt{t}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.03756em;vertical-align:-0.93em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1075599999999999em;\"><span style=\"top:-2.21746em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.89254em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord mathnormal\">t</span></span></span><span style=\"top:-2.85254em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.14746000000000004em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<ul>\n<li>初期下降很快</li>\n<li>之后衰减慢</li>\n<li>用于 Transformer</li>\n</ul>\n<hr />\n<p><a href=\"%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%88%AA\">&lt;返回深度学习导航</a></p>\n","feature":false,"text":"关于深度学习中学习率的作用和调整方法的笔记。...","permalink":"/post/笔记/深度学习/学习率","photos":[],"count_time":{"symbolsCount":"1.1k","symbolsTime":"1 mins."},"categories":[{"name":"笔记-深度学习","slug":"笔记-深度学习","count":12,"path":"api/categories/笔记-深度学习.json"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":13,"path":"api/tags/Machine-Learning.json"},{"name":"Deep Learning","slug":"Deep-Learning","count":13,"path":"api/tags/Deep-Learning.json"},{"name":"Learning Rate","slug":"Learning-Rate","count":1,"path":"api/tags/Learning-Rate.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%80-%E5%AD%A6%E4%B9%A0%E7%8E%87\"><span class=\"toc-text\"> 一. 学习率</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BA%8C-%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E5%BA%A6\"><span class=\"toc-text\"> 二. 学习率调度</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-%E9%98%B6%E6%A2%AF%E8%A1%B0%E5%87%8F\"><span class=\"toc-text\"> 1. 阶梯衰减</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-%E4%BD%99%E5%BC%A6%E8%A1%B0%E5%87%8F\"><span class=\"toc-text\"> 2. 余弦衰减</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-%E7%BA%BF%E6%80%A7%E8%A1%B0%E5%87%8F\"><span class=\"toc-text\"> 3. 线性衰减</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#4-%E9%80%86%E5%B9%B3%E6%96%B9%E6%A0%B9%E8%A1%B0%E5%87%8F\"><span class=\"toc-text\"> 4. 逆平方根衰减</span></a></li></ol></li></ol>","author":{"name":"zExNocs","slug":"blog-author","avatar":"/img/avatar.jpg","link":"/","description":"<p>一个喜欢摸鱼的人。<br>去码头整点薯条。</p>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"github":{"icon":"/img/svg/github.svg","link":"https://github.com/zExNocs"},"bilibili":{"icon":"/img/svg/bilibili.svg","link":"https://space.bilibili.com/13423200"},"steam":{"icon":"/img/svg/steam.svg","link":"https://steamcommunity.com/id/zExNocs/"}}}},"mapped":true,"hidden":false,"prev_post":{"title":"深度学习-优化器","uid":"9d23ccc00b1ad8b23cfee64325a0d6fb","slug":"笔记/深度学习/优化器","date":"2025-12-26T01:00:25.000Z","updated":"2025-12-27T03:00:11.525Z","comments":true,"path":"api/articles/笔记/深度学习/优化器.json","keywords":null,"cover":"img/post/笔记/深度学习/优化器/cover.jpg","text":"关于深度学习中优化器的原理和常用类型的笔记。优化器用于使用偏导数更新神经网络的权重参数，以最小化损失函数。...","permalink":"/post/笔记/深度学习/优化器","photos":[],"count_time":{"symbolsCount":"15k","symbolsTime":"13 mins."},"categories":[{"name":"笔记-深度学习","slug":"笔记-深度学习","count":12,"path":"api/categories/笔记-深度学习.json"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":13,"path":"api/tags/Machine-Learning.json"},{"name":"Deep Learning","slug":"Deep-Learning","count":13,"path":"api/tags/Deep-Learning.json"},{"name":"Optimizer","slug":"Optimizer","count":1,"path":"api/tags/Optimizer.json"}],"author":{"name":"zExNocs","slug":"blog-author","avatar":"/img/avatar.jpg","link":"/","description":"<p>一个喜欢摸鱼的人。<br>去码头整点薯条。</p>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"github":{"icon":"/img/svg/github.svg","link":"https://github.com/zExNocs"},"bilibili":{"icon":"/img/svg/bilibili.svg","link":"https://space.bilibili.com/13423200"},"steam":{"icon":"/img/svg/steam.svg","link":"https://steamcommunity.com/id/zExNocs/"}}}},"feature":false},"next_post":{"title":"深度学习-感知机","uid":"b81331e08fcec528371eb36f68471d43","slug":"笔记/深度学习/感知机","date":"2025-12-25T23:50:03.000Z","updated":"2025-12-29T05:48:30.908Z","comments":true,"path":"api/articles/笔记/深度学习/感知机.json","keywords":null,"cover":"img/post/笔记/深度学习/感知机/cover.png","text":"关于深度学习中感知机和Adaline模型的笔记...","permalink":"/post/笔记/深度学习/感知机","photos":[],"count_time":{"symbolsCount":"9.4k","symbolsTime":"9 mins."},"categories":[{"name":"笔记-深度学习","slug":"笔记-深度学习","count":12,"path":"api/categories/笔记-深度学习.json"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","count":13,"path":"api/tags/Machine-Learning.json"},{"name":"Deep Learning","slug":"Deep-Learning","count":13,"path":"api/tags/Deep-Learning.json"},{"name":"Perceptron","slug":"Perceptron","count":1,"path":"api/tags/Perceptron.json"}],"author":{"name":"zExNocs","slug":"blog-author","avatar":"/img/avatar.jpg","link":"/","description":"<p>一个喜欢摸鱼的人。<br>去码头整点薯条。</p>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"github":{"icon":"/img/svg/github.svg","link":"https://github.com/zExNocs"},"bilibili":{"icon":"/img/svg/bilibili.svg","link":"https://space.bilibili.com/13423200"},"steam":{"icon":"/img/svg/steam.svg","link":"https://steamcommunity.com/id/zExNocs/"}}}},"feature":false}}