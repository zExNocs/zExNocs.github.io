[{"id":"c0a95ceab12c74bbb654e3403dd31ec5","title":"笔记-游戏开发笔记","content":"","slug":"笔记-游戏开发笔记","date":"2024-06-09T23:25:51.000Z","categories_index":"Cate","tags_index":"Tag","author_index":"zExNocs"},{"id":"43a3c4ed23195bb672e40c41942223f5","title":"随笔-如何提交文章到VoidGameSpace上","content":"本文章仅适用于VoidGameSpace论坛及其GitHub库。\n该教程目前仅适用于Windows系统。\n官方博客传送面板\n 如何使用github进行提交\n 一. 确认Git安装\nGit下载地址: Link\n测试Git：打开 cmd 或者 PowerShell，输入 git -v 可以查看到当前Git的版本。\n 二. 配置Git设置和SSH\n\n使用下面两个指令配置Git全局设置：\n\n12git config --global user.name &quot;你的用户名&quot;git config --global user.email &quot;你的邮箱&quot;\n\n配置ssh设置：可以参考这个文章\n\n\n使用 ssh-keygen -t rsa -C &quot;你的邮箱&quot;，一路回车生成SSH。\n找到文件C:\\User\\用户名\\.ssh\\id_rsa.pub，使用记事本打开并复制里面的内容。\n打开GitHub在Settings界面左边找到SSH and GPG keys进入。\n点击 New SSH key，在title中填入合适的标题，在SSH中填入刚刚复制的内容。\n本地指令输入 ssh -T git@github.com 验证是否配置成功。\n\n 三. fork库到自己的库中\n打开 GitHub库 网页，点击右上角 Fork 按钮，复制该库到自己的库中。\n选择owner为自己的账户，Repository name可以设置为默认GameDevWebsite。\nDescription用来描述这个库，可以随便写一些，例如：VoidGameSpace论坛的Fork库。\n点击 Create fork 按钮。\n 四. clone库到本地\n进入自己的库中找到刚刚fork的GameDevWebsite库，一般为 https://github.com/用户名/GameDevWebsite\n找到 &lt;&gt; Code 绿色按钮，在本地中使用 PowerShell 打开想要部署的位置 or 在部署的位置中右键选择在终端打开 or 使用cmd cd 到要部署的文件夹，使用下面三种方式之一克隆库到本地\n\n使用HTTPS，复制web URL，输入git clone 复制的URL部署。这个方法需要你在终端登录到Git中。\n使用SSH，复制SSH key，输入git clone 复制的SSH_key部署。\n点击Download ZIP，下载压缩包到要部署的文件夹并解压。\n\n 五. 编写自己的文档\n在部署的项目目录GameDevWebsite中，路径source\\_posts\\创建自己的文件夹，并在文件夹中创建.md文件，参考GitHub库中元数据说明，编写自己的文章。\n另外，markdown的编写可以参考官方文档：Link\n 六. 提交文档到自己fork的库中\n使用 PowerShell 打开项目目录GameDevWebsite，或者在目录中右键点击在终端打开，或者使用cmd cd到目录。\n\n创建自己的分支(可选，新手建议直接修改main分支)：使用 git checkout -b 分支名 创建并切换到新的分支。(分支的作用是保证main分支的干净，一般只有最终版本才会合并到main分支)。如果你已经创建过分支，就不需要再创建该分支了。\n添加所有文件到暂存区： git add .\n提交添加的文件： git commit -m &quot;修改描述&quot;。为了养成好习惯，修改描述要有一定的准则。例如你修改文档可以写 &quot;docs(你的名字): 添加了xxx文章&quot;。具体准则可以自行搜索学习一下。\npush库：如果你使用的是新建的分支，使用git push origin 分支名 将新分支push到库中。如果你使用的是main分支或者是已经创建的库，那么使用 git push 将提交的内容push到库中。\n\n 七. 拉取申请\n找到自己fork的库，点击左上方 Pull requests按钮，进入页面点击右上方New pull request按钮。左边是合并的基库，右边是申请合并的库。在右边申请的库中选择自己的库和分支(如果没有创建分支就选择main)，然后填写一些申请描述即可。\n 八. 等待审核\n建议留言压力v佬(bushi)\n","slug":"随笔/随笔-如何提交文章到VoidGameSpace上","date":"2024-05-28T07:06:44.000Z","categories_index":"随笔","tags_index":"VoidGameSpace,Hexo","author_index":"zExNocs"},{"id":"ed2691e46b19986acffbcbe7e26041d1","title":"随笔-让Aurora支持KaTeX和Emoji","content":" ✒️背景\n最早接触markdown是在洛谷的个人博客时使用的。其中有一个功能我特别喜欢用，就是用$$符号展示出的公式，类似于这样：f(x)=eΔkTf(x)=e^{\\frac{\\Delta}{kT}}f(x)=ekTΔ​，以至于以后只要用到有关字母公式的地方就会喜欢性地打出$$。\n但是我在使用Aurora的时候，发现它并不能直接使用$$公式，研究发现是Hexo默认的markdown渲染器不支持KaTeX，故有此文章来研究如何让Hexo支持。\n 🔖内容\nHexo的markdown渲染器有很多种：Hexo多种Markdown渲染器对比分析。\nHexo自带的markdown渲染器不支持KaTeX，也不支持emoji。而网络上常见的pandoc在部署到Aurora时会出现很多问题。这里我使用的是markdown-it-plus，它原生就支持emoji和KaTeX插件。具体步骤如下：\n\n卸载原生渲染器 npm un hexo-renderer-marked --save\n安装新渲染器 npm i hexo-renderer-markdown-it-plus --save\n添加选项：在根目录下_config.yml添加以下字段：\n\n12345678910markdown_it_plus:    highlight: true    html: true    xhtmlOut: true    breaks: true    langPrefix:    linkify: true    typographer:    quotes: “”‘’    pre_class: highlight\n\n添加css：在根目录下_config.aurora.yml找到injects字段，并添加css，参考如下：\n\n12345678#! ---------------------------------------------------------------#! Injections#! @docs https://aurora.tridiamond.tech/guide/site-meta.html#custom-meta#! ---------------------------------------------------------------injects:  scripts:  css:    - &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css&quot;&gt;\n\n清理并重新生成Hexo hexo clean &amp; hexo g -d\n\n 📘Reference\n\nHexo多种Markdown渲染器对比分析: https://zsyyblog.com/b73ceb85.html\nhexo-renderer-markdown-it-plus官方文档：https://github.com/CHENXCHEN/hexo-renderer-markdown-it-plus\nAurora官方插件文档：https://aurora.tridiamond.tech/cn/configs/site-meta.html\n\n","slug":"随笔/随笔-让Hexo支持KaTeX和Emoji","date":"2024-05-27T06:05:16.000Z","categories_index":"随笔","tags_index":"Hexo","author_index":"zExNocs"},{"id":"dd909d4f3bf029c1efe5bae0e6ec00d1","title":"随笔-记录网友怪话","content":"←返回导航\n\n\n\n\n","slug":"随笔/随笔-记录网友怪话","date":"2024-05-25T07:52:15.000Z","categories_index":"随笔","tags_index":"Essay","author_index":"zExNocs"},{"id":"ca919ca5c3402d033970c77af27cf3c5","title":"随笔-梗图","content":"←返回导航\n 娱乐向\n\n\n\n\n\n\n\n\n 提问向\n\n\n提问的艺术\n\n\n\n提问收费表\n\n\n\n","slug":"随笔/随笔-梗图","date":"2024-05-25T06:55:45.000Z","categories_index":"随笔","tags_index":"Essay","author_index":"zExNocs"},{"id":"49266c0927eaad653ea21227e55d59fb","title":"LAC - Formal Languages and Automata Theory 形式语言与自动机理论","content":" 背景\n课程原名为Languages and Computation(语言与计算)，但是这很明显是一个比较笼统的名字。本课程的主要内容还是将有关形式语言与自动机理论的知识。\n关于自动机，早在学习算法竞赛的时候有学过AC自动机(Aho-Corasick automaton, 是字典树 + KMP算法 + 自动机的结合)的知识，但是并没有建立有关自动机的系统性概念。\n此外，在学习做游戏AI的时候，有接触过关于状态设计模式的概念，游戏AI是一个巨大的状态自动机，因此我也利用这个方法在我CPP课程的游戏里设计了敌人的AI，具体可以参考这个笔记: 简单游戏引擎开发笔记。\n 介绍\n本笔记主要分为下面几个部分(并不是按照课程顺序排序，而是相似课程归纳)：\n","slug":"笔记/笔记-LAC-形式语言与自动机","date":"2024-05-25T03:53:20.000Z","categories_index":"笔记","tags_index":"Notes,Automata Theory,Formal Languages,Theory","author_index":"zExNocs"},{"id":"ca7a89ba385cdbc1ce7b55d4c88122bd","title":"AIM - Optimization 优化算法","content":" 背景\n课程原名为Artificial Intelligence Methods(人工智能方法)，但实际上内容都是有关一些优化算法的内容，相比如今环境下主流的大模型、神经网络还是相差甚远。因为部分优化算法中也具备一些学习能力（比如说遗传算法），因此也可以被视为一种弱人工智能。\n 介绍\n本笔记主要分为下面几个部分(并不是按照课程顺序排序，而是相似课程归纳)：\n1234567#include&lt;bits/stdc++.h&gt;using namespace std;int main() &#123;  printf(&quot;Hello World!&quot;);  return 0;&#125;","slug":"笔记/笔记-AIM-优化算法","date":"2024-05-25T03:52:11.000Z","categories_index":"笔记","tags_index":"Algorithm,AI,Optimization","author_index":"zExNocs"},{"id":"8e94a57200662cea86ae71df183554b9","title":"ADE - Algorithms Data Structures and Efficiency 算法数据结构和效率","content":" ✒️背景\n早在一年前就知道了这个有关算法和数据结构的课程。作为一个退役OIer，之前有接触过关于这个课程的内容，比如堆、图论等，因此是对这个课程具有很大兴趣的。\n不过这个课程并不是集中于讲解算法和数据结构，而是着重于使用理论对算法效率的分析，比如Big-Oh表示法。学算法竞赛的时候只是经常听说过和使用过时间复杂度、空间复杂度，不过一直以来对它们的理解都停留在算法在时间和空间上对某一或多种变量/输入的增长程度上，可以说是对这一类知识处于一种一知半解的状态。\n建议使用右边的导航选择性地阅读。\n 🔖介绍\n本笔记着重于介绍使用理论知识分析算法和数据结构的效率，此外还会介绍一些算法和数据结构的抽象功能，以及对这些功能实现的效率分析。\n本笔记主要分为下面四个部分(并不是按照课程顺序排序，而是相似课程归纳)：\n\n一. 算法效率的评估\n二. Big-Oh表示法和其家族\n三. Master定理\n四. 数据结构\n五. 算法\n\n 一. 🔬算法效率的评估\n如何评估一个算法的效率？最直接的方式就是在程序输入后何时才能获得输出值。其中一种比较直观的方式是根据 程序的运行时间 来评估测量算法效率。\n在同一个程序中，程序的运行时间往往会随着输入大小(input size)而增加。即使固定输入大小，实际运行时间通常也会有所不同，这取决于输入的详细信息。例如在最短路算法中，即使是相同数量的点和边，不同的连接方法也会导致运行时间不同 (关于SPFA，它死了) 。\n由于你的时间非常值钱，因此我们需要一些方法来对算法的效率进行客观地评估，这些方法主要可以分类为两种：实验统计和理论分析。\n\n 方法一：Experiment 实验统计\n\n\n\n\n\n\n\n\n\n\n实验统计是使用观察和控制变量的方法来对一种现象进行系统的测试和验证。\n具体步骤如下:\n\n写一个程序实施该算法\n使用不同的输入大小和输入信息运行程序\n记录实际运行时间\n绘制并使用统计学分析（如回归分析）\n\n在固定输入大小、不同输入信息中，统计中获得最佳运行时间、最差运行时间、平均运行时间，我们通常会关注最差的情况，主要原因是平均时间往往很难以去分析 (例如为什么在判断一个公司工资待遇往往不是使用平均值，更多的是最低工资)。\n 缺点 &amp; 局限性\n\n必须用程序实现该算法，可能会很耗时。\n需要提供大量输入集或者选择合适的输入集来找到最差的情况，不然会导致结果的偏差。\n效率的评估受到硬件/软件/语言环境的影响。\n\n\n 方法二：Theory 理论分析\n\n\n\n\n\n\n\n\n\n理论分析是基于已有的知识和数据，运用逻辑和数学的方法来对一种现象进行解释和预测。\n跟实验统计一样，我通常指关注最差的情况。\n 特点\n\n具有一定的抽象性。\n能够独立于硬件/软件/语言环境来评估算法的效率。\n能够考虑所有可能的输入。\n\n 缺点 &amp; 局限性\n\n实施过程可能会比较困难，需要一定的知识基础。\n在现实实施的时候可能有一些特殊情况导致与理论结果相差较大，使用理论解释这种情况可能会比较困难。\n\n 评估标准\n在实验统计中，我们往往使用 程序的运行时间 来作为评估的标准，但是在理论知识中我们无法使用这个来作为评估标准。因为程序的运行时间往往受到环境的影响，因此理论难以测量出运行时间，所以我们使用另一种方法来作为理论分析中使用的评估标准：原始运算数量。\n 原始运算的定义\n\n\n\n\n\n\n\n\n\n原始运算(primitive operations)是算法执行的基本运算。\n在真实的计算机中，实际的运算应该是逻辑门的操作，但是很明显这个是很琐碎的，与算法的运算相差太远。因此我们需要去定义哪些运算属于原始运算以便于记数。一般来说，我们会将汇编代码、算数运算视作一个原始运算。\n注意，原始运算的定义不是固定的，下面有更具体的说明。在这个笔记中，我们将这些操作视作一个原始运算：\n\n\n\n描述\n伪代码样例\n\n\n\n\n变量赋值\na ← 0\n\n\n数组索引\na[10]\n\n\n变量比较\na == 10\n\n\n算数运算\na + 1\n\n\n函数调用\nfunction()\n\n\n函数返回\nreturn 0\n\n\n\n注意：\n\n在本笔记中我们忽视了汇编中有关jump的指令，即本笔记中默认jump指令原始运算为0。\n数组索引需要用到袁术运算是因为它需要在内存中进行索引。\n函数调用属于原始运算是因为它需要在内存中进行索引。\n在CPU中，浮点运算(如除法)实际上是一个非常复杂的算法。但在汇编语言中，它只是一个指令，因此我们也将其视作一个原始运算。\n\n对于其他的运算，都可以拆分为这些原始运算：\n\n\n\n描述\n分析\n操作数\n伪代码样例\n\n\n\n\nfor循环，循环次数为nnn\n要经历1次初始赋值；n次判断；n次叠加，每次叠加是两个原始运算(加法和赋值)\n1+n+2n=3n+11+n+2n = 3n+11+n+2n=3n+1\nfor i ← 1 to n do\n\n\nfor循环，循环次数为(n−1)(n-1)(n−1)\n要经历1次初始赋值；(n-1)次判断，每次判断是两个原始运算(减法和比较)；(n-1)次叠加，每次叠加是两个原始运算(加法和赋值)\n1+2(n−1)+2(n−1)=4n−31+2(n-1)+2(n-1) = 4n-31+2(n−1)+2(n−1)=4n−3\nfor i ← 1 to (n-1) do\n\n\nwhile循环，循环次数为nnn\n每次循环只需要判断即可\nnnn\nwhile i &gt; n\n\n\nwhile循环，循环次数为(n−1)(n-1)(n−1)\n每次循环都需要进行判断和减法\n2(n−1)2(n-1)2(n−1)\nwhile i &gt; (n-1)\n\n\nif then判断，then内部原始运算数为kkk\n一个判断。由于我们是统计最差次数，因此我们需要将if里原始运算进行累加(默认触发)\n1+k1 + k1+k\nif ... then ...\n\n\n\n\n一个计算原始运算数的例子: arrayMax(A, n)\n一个返回数组最大值arrayMax(A, n)的伪代码：\n123456Algorithm arrayMax(A, n)    # A为数组，n为数组大小，即数组从0开始，(n-1)结束。  currentMax ← A[0]         # 原始运算数为2，分别是数组索引和赋值  for i ← 1 to (n - 1) do   # (n-1)次数的循环运算，原始运算数为(4n-3)    if A[i] &gt; currentMax    # 每次循环原始运算数为2，分别是数组索引和判断，共(n-1)次循环，原始运算数为2(n-1)      currentMax ← A[i]     # then内部运算。每次循环原始运算数为2，分别是数组索引和赋值，原始运算数为2(n-1)  return currentMax         # 原始运算为1，函数返回\n综上所述，这个算法的原始运算总数为 2+(4n−3)+2(n−1)+2(n−1)+1=8n−42 + (4n - 3) + 2(n - 1) + 2(n - 1) + 1 = 8n - 42+(4n−3)+2(n−1)+2(n−1)+1=8n−4\n\n\n原始运算的个数并不是固定的，例如在计算操作 c←A[i]c \\leftarrow A[i]c←A[i] 中，你也可以认为是444个原始运算：\n\n获取AAA数组的指针储存在寄存器中。\n获取iii储存在寄存器中。\n计算A+iA + iA+i作为A[i]A[i]A[i]的指针储存在寄存器中。\n复制变量ccc的数值写在A+iA + iA+i指针的内存中。\n\n当然在这个笔记中，你也可以认为只有222个原始运算：\n\n根据iii索引获取A[i]A[i]A[i]数组位置 (数组索引)。\n将变量ccc的数值赋值给A[i]A[i]A[i] (变量赋值)。\n\n但是无论是444还是222，这个操作永远不可能会是2n2n2n，即它的增长率永远不可能会超过常数级(增长率的定义在下面)。\n\n\n\n\n\n\n\n\n\n原始运算的个数只与算法的效率有关，与正确性无关。\n 使用原始运算估算运行时间\n增长率(Growth Rate)指的是函数的因变量随着自变量的增加而增长的速率。\n\n\n\n\n\n\n\n\n\n对于算法来说，假设它的最差情况的运行时间为T(n)T(n)T(n)，那么T(n)T(n)T(n)的增长率是该算法的固有属性，是不受硬件/软件环境影响的。\n我们可以使用原始运算来估算运行时间，假设：\n\n原始运算的个数为P(n)P(n)P(n)。\n最快的原始运算所需要的时间为aaa，是一个常数。\n最慢的原始运算所需要的时间为bbb，是一个常数。\n\n可以得出：aP(n)≤T(n)≤bP(n)aP(n) \\leq T(n) \\leq bP(n)aP(n)≤T(n)≤bP(n)\n由于a和b都是常数，那么我们认为T(n)T(n)T(n)和P(n)P(n)P(n)具有相同的增长率。很明显T(n)T(n)T(n)和P(n)P(n)P(n)的导数肯定是不同的，因此增长率并不等同于导数。\n但是增长率有一种只可意会不可言传的感觉：这种增长率具体形式是什么样的？如何定义哪两个函数具有相同的增长率？那么就需要用到我们的Big-Oh表示法了。\n 二. 🏠Big-Oh表示法和其家族\n 基本知识\n我们需要一种函数分类(Classification of Functions)来通过缩放的行为将函数分组在一起，同一组的函数具有这样的相似性：\n\n删除不必要的细节。\n相对快速、简单。\n处理运行时可能会发生的“奇怪的”函数(例如分段函数)。\n在数学上拥有明确的定义。\n\n其中一种最佳的方法是使用Big-Oh表示法和其家族(Big-Oh notation and family)：\n\nOOO: Big-Oh\nΩ\\OmegaΩ: Big-Omega\nΘ\\ThetaΘ: Big-Theta\nooo: little-oh\nω\\omegaω: little-omega\n\n本笔记只集中于前四个的定义和Big-Oh的相关理论。\n\n Big-Oh：O(n)\n 定义\n假设有两个正函数f(n)f(n)f(n)和g(n)g(n)g(n)，如果我们称 f(n) is O(g(n))f(n) \\ is \\ O(g(n))f(n) is O(g(n)) ，当且仅当\n\n\n\n\n\n\n\n\n\n∃c&gt;0,∃n0&gt;0,∀n≥n0:∣f(n)∣≤c g(n)\\exist c &gt; 0, \\exist n_0 &gt; 0, \\forall n \\geq n_0 : |f(n)| \\color{red} \\boldsymbol{ \\leq } \\color{black} c \\ g(n)\n∃c&gt;0,∃n0​&gt;0,∀n≥n0​:∣f(n)∣≤c g(n)\n注意:\n\n量词顺序是 ∃ ∃ ∀\\exist \\ \\exist \\ \\forall∃ ∃ ∀\nccc 和 n0n_0n0​必须是常数，不能随着nnn变化。不然这是没有意义的。\n注意符号&gt;,≥,≤&gt;,\\geq,\\leq&gt;,≥,≤的区分。相比之下是比较严格的(例如，n0n_0n0​ 不能等于 000, nnn 可以等于 n0n_0n0​)。\n\n此外，Big-Oh可以会被定义为：\nlim sup⁡n→∞f(n)g(n)&lt;∞\\limsup_{n\\to \\infty} \\frac{f(n)}{g(n)} &lt; \\infty \nn→∞limsup​g(n)f(n)​&lt;∞\n\n\n\n\n\n\n\n\n\nBig-Oh只规定了f(n)f(n)f(n)的增长率的上限(upper bound on the growth rate of the function)。\n 特点\n\nBig-Oh不关注算法或者是“算法最差的运行时间”，而是只关注于函数。也就是说它并不是对算法进行分类，而是对函数进行分类。\n一般f(n)f(n)f(n)表示运行时间，nnn表示输入的个数，所以Big-Oh中描述的函数一般为 f:N+→R+f: \\mathbb{N^+} \\to \\mathbb{R^+}f:N+→R+，g(n)g(n)g(n)也类似。\nBig-Oh只规定了f(n)f(n)f(n)的增长率的上限，也就是说，当nnn足够大时，f(n)f(n)f(n)的增长速率不大于g(n)g(n)g(n)。\nBig-Oh中g(n)g(n)g(n)的选择并不是一定要选择“最佳”或者“最有用的”函数。例如，对于f(n)=1f(n) = 1f(n)=1可以是O(1)O(1)O(1)，但也可以是O(n)O(n)O(n)。因此g(n)g(n)g(n)的增长率越小越能反应出f(x)f(x)f(x)的增长率。\n\n 性质\nBig-Oh作为一个二元关系(binary relation)，拥有以下性质：\n\nBig-Oh具有自反性(Reflexive, e.g. xRxx R xxRx)，即 f(n)f(n)f(n) 是 O(f(n))O(f(n))O(f(n))。\nBig-Oh不具有对称性(Symmetric, e.g. xRy  ⟺  yRxx R y \\iff y R xxRy⟺yRx)，例如 f(n)=1f(n) = 1f(n)=1 是 O(n)O(n)O(n)，但是 f(n)=nf(n) = nf(n)=n 不是 O(1)O(1)O(1)。\nBig-Oh具有传递性(Transitive, e.g. xRy  &amp;  yRz→xRzx R y \\ \\ \\&amp; \\ \\ y R z \\to xRzxRy  &amp;  yRz→xRz)。即如果 ∀n≥n1,f(n)≤c1g(n)\\forall n \\geq n_1, f(n) \\leq c_1g(n)∀n≥n1​,f(n)≤c1​g(n)，且∀n≥n2,g(n)≤c2h(n)\\forall n \\geq n_2, g(n) \\leq c_2h(n)∀n≥n2​,g(n)≤c2​h(n)，那么总有 ∀n≥n3,f(n)≤c1c2h(n),n3=max⁡(n1,n2)\\forall n \\geq n_3, f(n) \\leq c_1c_2h(n), n_3=\\max(n_1,n_2)∀n≥n3​,f(n)≤c1​c2​h(n),n3​=max(n1​,n2​)。\n\n综上所述，Big-Oh具有自反性和传递性，因此Big-Oh更像是⊂,∈,≤\\subset, \\in, \\leq⊂,∈,≤,而不是===，因此有一种表示方法是将Big-Oh视作集合，使用n∈O(n)n \\in O(n)n∈O(n)。此时也有会 O(lower_order)⊂O(heigher_order)O(lower\\_ order) \\subset O(heigher\\_ order)O(lower_order)⊂O(heigher_order)。\n此外，也有一种说法是使用f(n)=O(n)f(n) = O(n)f(n)=O(n)，其中等于号是一种单向的等于。但是本笔记中更偏向于使用“是”或者“is”来表示。\n 推论 &amp; 方法\n\n推论1：存在三个函数f(n)f(n)f(n), g(n)g(n)g(n), p(n)p(n)p(n)和正数k,b∈N+k, b\\in \\mathbb{N^+}k,b∈N+，如果f(n)f(n)f(n)是O(g(n))O(g(n))O(g(n))，且f(n)=k p(n)+bf(n)=k\\ p(n) + bf(n)=k p(n)+b，那么有p(n)p(n)p(n)是O(g(n))O(g(n))O(g(n))。\n\n\n证明推论1\n假设有c0&gt;0,n0&gt;0c_0 &gt; 0, n_0 &gt; 0c0​&gt;0,n0​&gt;0，对于n1≥n0n_1 \\geq n_0n1​≥n0​，有：\nf(n1)≤c0 g(n1)f(n_1) \\leq c_0 \\ g(n_1)f(n1​)≤c0​ g(n1​)，那么有：\nk p(n1)+b≤c0 g(n1)k\\ p(n_1) + b \\leq c_0 \\ g(n_1)k p(n1​)+b≤c0​ g(n1​)，整理得：\np(n1)≤c0kg(n1)−bkp(n_1) \\leq \\frac{c_0}{k}g(n_1) - \\frac{b}{k}p(n1​)≤kc0​​g(n1​)−kb​\n当n足够大时候，假设此时n1≥n2n_1 \\geq n_2n1​≥n2​，有 cg(n1)≥2bcg(n_1) \\geq 2bcg(n1​)≥2b\n从而有 p(n1)≤c02kg(n1)p(n_1) \\leq \\frac{c_0}{2k}g(n_1)p(n1​)≤2kc0​​g(n1​)\n设 c1=c2k&gt;0c_1=\\frac{c}{2k}&gt;0c1​=2kc​&gt;0，我们得到：\np(n1)≤c1 g(n1)p(n_1) \\leq c_1\\ g(n_1)p(n1​)≤c1​ g(n1​)，即\n存在 c1c_1c1​，n2n_2n2​使得 ∀n&gt;n2,p(n)≤c1 g(n)\\forall n &gt; n_2, p(n) \\leq c_1\\ g(n)∀n&gt;n2​,p(n)≤c1​ g(n)\n因此p(n)p(n)p(n)是O(g(n))O(g(n))O(g(n))。\n\n\n\n推论2 （乘法）：如果f1(n)f_1(n)f1​(n) 是 O(g1(n))O(g_1(n))O(g1​(n)), f2(n)f_2(n)f2​(n) 是 O(g2(n))O(g_2(n))O(g2​(n))，那么 f1(n)f2(n)f_1(n)f_2(n)f1​(n)f2​(n) 是 O(g1(n)g2(n))O(g_1(n)g_2(n))O(g1​(n)g2​(n))。\n\n\n证明推论2\n∵f1(n)∵ f_1(n)∵f1​(n) 是 O(g1(n))O(g_1(n))O(g1​(n))\n∴f1(n)≤c1 g1(n)  for all  n≥n1∴ f_1(n) \\leq c_1\\ g_1(n)\\ \\text{ for all } \\ n \\geq n_1∴f1​(n)≤c1​ g1​(n)  for all  n≥n1​\n∵f2(n)∵ f_2(n)∵f2​(n) 是 O(g2(n))O(g_2(n))O(g2​(n))\n∴f2(n)≤c2 g2(n)  for all  n≥n2∴ f_2(n) \\leq c_2\\ g_2(n)\\ \\text{ for all } \\ n \\geq n_2∴f2​(n)≤c2​ g2​(n)  for all  n≥n2​\n∵f1(n),f2(n),g1(n),g2(n)≥0∵ f_1(n), f_2(n), g_1(n), g_2(n) \\geq 0∵f1​(n),f2​(n),g1​(n),g2​(n)≥0\n那么有 n0=max⁡(n1,n2)n_0 = \\max(n_1, n_2)n0​=max(n1​,n2​)\nf1(n)f2(n)≤c1c2g1(n)g2(n)  for all  n≥n0f_1(n)f_2(n) \\leq c_1c_2g_1(n)g_2(n) \\ \\text{ for all } \\ n \\geq n_0f1​(n)f2​(n)≤c1​c2​g1​(n)g2​(n)  for all  n≥n0​\n因此f1(n)f2(n)f_1(n)f_2(n)f1​(n)f2​(n) 是 O(g1(n)g2(n))O(g_1(n)g_2(n))O(g1​(n)g2​(n))\n\n\n\n推论3 （加法）：如果 f(n)=1+h(n)f(n) = 1 + h(n)f(n)=1+h(n)，且当n→∞n \\to \\inftyn→∞ 时 h(n)→0h(n) \\to 0h(n)→0，那么 f(n)f(n)f(n) 是 O(1)O(1)O(1)。\n\n\n证明推论3\n∵∵∵ 当n→∞n \\to \\inftyn→∞ 时 h(n)→0h(n) \\to 0h(n)→0\n∴∴∴ ∃n0&gt;0, ∀n≥n0,h(n)≤1\\exist n_0 &gt; 0,\\ \\forall n \\geq n_0, h(n) \\leq 1∃n0​&gt;0, ∀n≥n0​,h(n)≤1\n∴∴∴ ∃n0&gt;0, ∀n≥n0,f(n)≤2\\exist n_0 &gt; 0,\\ \\forall n \\geq n_0, f(n) \\leq 2∃n0​&gt;0, ∀n≥n0​,f(n)≤2\n∴∴∴ f(n)f(n)f(n) 是 O(1)O(1)O(1) 取 c=2,n0=n1c = 2, n_0 = n_1c=2,n0​=n1​ 且 h(n1)&lt;=1h(n_1) &lt;= 1h(n1​)&lt;=1\n\n\n一些常用的 h(n)h(n)h(n):\n\nn2/2nn^2/2^nn2/2n\nn2000/2n100n^{2000}/2^{\\frac{n}{100}}n2000/2100n​\n(log(n))100/n0.1(log(n))^{100} / n^{0.1}(log(n))100/n0.1\n\n综合推论2和3，可知如果 f(n)=g(n)(1+h(n))f(n) = g(n)(1 + h(n))f(n)=g(n)(1+h(n))，且当n→∞n \\to \\inftyn→∞ 时 h(n)→0h(n) \\to 0h(n)→0，那么 f(n)f(n)f(n) 是 O(g(n))O(g(n))O(g(n))。\n因此我们总结了获取Big-Oh的通用方法 —— 删除规则(Drop Rules)：\n\n删除低阶(lower-order)项 (根据推论2, 3)。阶排名可以看下面常用表示表。\n删除常数(constant)项系数 (根据推论1,总能找到 kkk 使得系数变成 111)。\n\n 例子\n\n证明arrayMax(A, n)是 O(n)O(n)O(n) 的例子 (定义)\n由上述计算原始运算数的例子可知，arrayMax(A, n)的原始运算记数为 f(n)=8n−4f(n) = 8n - 4f(n)=8n−4\n设g(n)=ng(n) = ng(n)=n，因此需要求证 ∃c&gt;0,∃n0&gt;0,∀n≥n0,f(n)≤c g(n)\\exist c &gt; 0, \\exist n_0 &gt; 0, \\forall n \\geq n_0, f(n) \\leq c \\ g(n)∃c&gt;0,∃n0​&gt;0,∀n≥n0​,f(n)≤c g(n)，整理可得：\n{n≤4c−8c&gt;8n≥4c−8c&lt;8−4≤0c=8\\begin{cases}\nn \\leq \\frac{4}{c - 8} &amp; c &gt; 8 \\\\\nn \\geq \\frac{4}{c - 8} &amp; c &lt; 8 \\\\\n-4 \\leq 0 &amp; c = 8\n\\end{cases}\n⎩⎪⎪⎨⎪⎪⎧​n≤c−84​n≥c−84​−4≤0​c&gt;8c&lt;8c=8​\n由于我们规定是 ∀n≥n0\\forall n \\geq n_0∀n≥n0​，因此我们只能取 n≥8n \\geq 8n≥8。\n当我们取 n=8n = 8n=8时，很明显任意n0&gt;0n_0 &gt; 0n0​&gt;0都可以证明成立。此时我们可以取 n0=1n_0 = 1n0​=1。\n当我们取 n&gt;8n &gt; 8n&gt;8时，很明显任意n0&gt;4c−8n_0 &gt; \\frac{4}{c - 8}n0​&gt;c−84​都可以证明成立。此时我们可以取 n0=4c−8n_0 = \\frac{4}{c - 8}n0​=c−84​。\n实际上，上述情况只需要求出一组(c,n0)(c,n_0)(c,n0​)即可，因此我们可以直接取c=8,n0=1c = 8, n_0 = 1c=8,n0​=1。不过这里给出了一种选取(c,n0)(c,n_0)(c,n0​)的具体方法。\n因此arrayMax(A, n)的时间复杂度是 O(n)O(n)O(n)。\n\n\n\n对于分段函数Big-Oh的证明 (定义)\n如何计算下面函数的Big-Oh:\nf(n)={nif n is even1if n is oddf(n) = \n\\begin{cases}\nn &amp; \\text{if } n \\text{ is even} \\\\\n1 &amp; \\text{if } n \\text{ is odd}\n\\end{cases}\nf(n)={n1​if n is evenif n is odd​\n因为Big-Oh是规定的函数增长率的上限，因此我们应该取增长率最大的函数，即f(n)=nf(n) = nf(n)=n，此时当c=1,n0=1c = 1, n_0 = 1c=1,n0​=1可以证明出f(n)f(n)f(n)是O(n)O(n)O(n)，而无法证明出f(n)f(n)f(n)是O(1)O(1)O(1)。\n\n\n\n求 f(n)=n2+nf_(n) = n^2 + nf(​n)=n2+n 的Big-Oh (定理2, 3)\nf(n)=n2+n=n2(1+1n)f(n) = n^2 + n = n^2(1 + \\frac{1}{n})f(n)=n2+n=n2(1+n1​)\n因为自反性，n2n^2n2 是 O(n2)O(n^2)O(n2)。\n因为当n→∞n \\to \\inftyn→∞ 时 1n→0\\frac{1}{n} \\to 0n1​→0，根据推理3可知 1+1n1 + \\frac{1}{n}1+n1​ 是 O(1)O(1)O(1)。\n因此根据推理2，f(n)f(n)f(n) 是 O(n2∗1)=O(n2)O(n^2 * 1) = O(n^2)O(n2∗1)=O(n2)\n\n\n\n求 f(n)=5n4+3n3f_(n) = 5n^4 + 3n^3f(​n)=5n4+3n3 的Big-Oh (删除规则)\n\n删除低阶3n3^n3n，因此f(n)f(n)f(n) 是 O(5n4)O(5n^4)O(5n4)\n删除常数555，因此f(n)f(n)f(n) 是 O(n4)O(n^4)O(n4)\n\n\n\n Big-Oh公约\n遵循这个公约可以更好地去分析算法以及给出最大的信息。\n\n使用最小且正确的增长率函数表示Big-Oh。例如说 2n2n2n 是 O(n)O(n)O(n) 而不是 O(n2)O(n^2)O(n2)，尽管后者也是正确的。\n使用最简的函数表示Big-Oh。例如说 2n2n2n 是 O(n)O(n)O(n) 而不是 O(2n)O(2n)O(2n)。\n\n 其他\n对于 nO(1)n^{O(1)}nO(1)来说，相当于是 {nf(n) ∣ f(n) is O(1)}\\{ n^f(n)\\ |\\ f(n) \\text{ is } O(1)\\}{nf(n) ∣ f(n) is O(1)}。\n也就是说 {n1,n2,n3,...}⊂nO(1)\\{n^1, n^2, n^3, ...\\} \\subset n^{O(1)}{n1,n2,n3,...}⊂nO(1)，{n12,n13,n14...}⊂nO(1)\\{n^\\frac{1}{2}, n^\\frac{1}{3}, n^\\frac{1}{4}... \\} \\subset n^{O(1)}{n21​,n31​,n41​...}⊂nO(1)\n\n\n\n\n\n\n\n\n\nnO(1)n^{O(1)}nO(1) is any function that is no worse than (Big-Oh of) some power law.\nnO(1)n^{O(1)}nO(1)表示任何不超过指数级的函数。\n\n Big-Omega：Ω(n)\n 定义\n假设有两个正函数f(n)f(n)f(n)和g(n)g(n)g(n)，如果我们称 f(n) is Ω(g(n))f(n) \\ is \\ \\Omega (g(n))f(n) is Ω(g(n)) ，当且仅当\n\n\n\n\n\n\n\n\n\n∃c&gt;0,∃n0&gt;0,∀n≥n0:f(n)≥c g(n)\\exist c &gt; 0, \\exist n_0 &gt; 0, \\forall n \\geq n_0 : f(n) \\color{red} \\boldsymbol{ \\geq } \\color{black} c \\ g(n)\n∃c&gt;0,∃n0​&gt;0,∀n≥n0​:f(n)≥c g(n)\n注意：\n\n量词顺序是 ∃ ∃ ∀\\exist \\ \\exist \\ \\forall∃ ∃ ∀。\n与Big-Oh不同，最后的符号是 ≥\\geq≥ 而不是 ≤\\leq≤。\n\n此外，Big-Omega可以会被定义为：\nlim inf⁡n→∞f(n)g(n)&gt;0\\liminf_{n\\to \\infty} \\frac{f(n)}{g(n)} &gt; 0 \nn→∞liminf​g(n)f(n)​&gt;0\n 特点\n\nBig-Omega规定了f(n)f(n)f(n)的增长率的下限，也就是说，当nnn足够大时，f(n)f(n)f(n)的增长速率不小于g(n)g(n)g(n)。\nBig-Omega中g(n)g(n)g(n)的选择并不是一定要选择“最佳”或者“最有用的”函数。例如，对于f(n)=n3−nf(n) = n^3 - nf(n)=n3−n 可以是 Ω(n3)\\Omega(n^3)Ω(n3)，但也可以是 Ω(n2)\\Omega(n^2)Ω(n2)。因此g(n)g(n)g(n)的增长率越大越能说明f(n)f(n)f(n)的增长率。\n一般可以用来描述算法的最佳情况。\n\n 性质\n类似于Big-Oh，Big-Omega作为一个二元关系拥有下面的性质：\n\nBig-Omega具有自反性(Reflexive, e.g. xRxx R xxRx)。\nBig-Omega不具有对称性(Symmetric, e.g. xRy  ⟺  yRxx R y \\iff y R xxRy⟺yRx)。\nBig-Omega具有传递性(Transitive, e.g. xRy  &amp;  yRz→xRzx R y \\ \\ \\&amp; \\ \\ y R z \\to xRzxRy  &amp;  yRz→xRz)。\n\nBig-Omega更像是 ≥\\geq≥。\n 推论 &amp; 方法\n\n推论1：f(n) is O(g(n))  ⟺  g(n) is Ω(f(n))f(n) \\text{ is } O(g(n))\\iff g(n) \\text{ is } \\Omega(f(n))f(n) is O(g(n))⟺g(n) is Ω(f(n))\n推论2 （乘法）：如果f1(n)f_1(n)f1​(n) 是 Ω(g1(n))\\Omega(g_1(n))Ω(g1​(n)), f2(n)f_2(n)f2​(n) 是 Ω(g2(n))\\Omega(g_2(n))Ω(g2​(n))，那么 f1(n)f2(n)f_1(n)f_2(n)f1​(n)f2​(n) 是 Ω(g1(n)g2(n))\\Omega(g_1(n)g_2(n))Ω(g1​(n)g2​(n))。\n\n删除规则依然适用于Big-Omega，但是注意删除法则跟Big-Oh一样是删除低阶函数而不是删除高阶函数。\n例如 f(n)=n3−nf(n) = n^3 - nf(n)=n3−n中，应该删除的是nnn。找到n3n^3n3后我们就可以找比n3n^3n3阶级低的函数来代替。\n\n Big-Theta：θ(n)\n 定义\n假设有两个正函数f(n)f(n)f(n)和g(n)g(n)g(n)，如果我们称 f(n) is Θ(g(n))f(n) \\ is \\ \\Theta (g(n))f(n) is Θ(g(n)) ，当且仅当\n\n\n\n\n\n\n\n\n\n∃c′&gt;0,∃c′′&gt;0,∃n0&gt;0,∀n≥n0:c′ g(n)≤f(n)≤c′′ g(n)\\exist c&#x27; &gt; 0, \\exist c&#x27;&#x27;&gt;0, \\exist n_0 &gt; 0, \\forall n \\geq n_0 : c&#x27;\\ g(n) \\leq f(n) \\leq c&#x27;&#x27; \\ g(n)\n∃c′&gt;0,∃c′′&gt;0,∃n0​&gt;0,∀n≥n0​:c′ g(n)≤f(n)≤c′′ g(n)\n此外，Big-Theta可以被定义为：\n\n\n\n\n\n\n\n\n\nf(n) is Θ(g(n))  ⟺  f(n) is O(g(n)) and f(n) is Ω(g(n))f(n) \\text{ is } \\Theta(g(n)) \\iff f(n) \\text{ is } O(g(n)) \\text{ and } f(n) \\text{ is } \\Omega(g(n))\nf(n) is Θ(g(n))⟺f(n) is O(g(n)) and f(n) is Ω(g(n))\nf(n) is Θ(g(n))  ⟺  f(n) is O(g(n)) and g(n) is O(f(n))f(n) \\text{ is } \\Theta(g(n)) \\iff f(n) \\text{ is } O(g(n)) \\text{ and } g(n) \\text{ is } O(f(n))\nf(n) is Θ(g(n))⟺f(n) is O(g(n)) and g(n) is O(f(n))\n 性质\nBig-Theta作为一个二元关系拥有下面的性质：\n\nBig-Theta具有自反性(Reflexive, e.g. xRxx R xxRx)。\nBig-Theta具有对称性(Symmetric, e.g. xRy  ⟺  yRxx R y \\iff y R xxRy⟺yRx)：如果 f(n)f(n)f(n) 是 Θ(g(n))\\Theta(g(n))Θ(g(n))，那么 g(n)g(n)g(n) 是 Θ(f(n))\\Theta(f(n))Θ(f(n))。可以根据Big-Theta的第二定义和Big-Omega的推论1得出。\nBig-Theta具有传递性(Transitive, e.g. xRy  &amp;  yRz→xRzx R y \\ \\ \\&amp; \\ \\ y R z \\to xRzxRy  &amp;  yRz→xRz)。\n\nBig-Theta更像是 ≈\\approx≈。\n\n little-oh：o(n)\n 定义\n假设有两个正函数f(n)f(n)f(n)和g(n)g(n)g(n)，如果我们称 f(n) is o(g(n))f(n) \\ is \\ o(g(n))f(n) is o(g(n)) ，当且仅当\n\n\n\n\n\n\n\n\n\n∀c&gt;0,∃n0&gt;0,∀n≥n0:∣f(n)∣&lt;c g(n)\\color{red} \\boldsymbol{ \\forall } \\color{black} c &gt; 0, \\exist n_0 &gt; 0, \\forall n \\geq n_0 : |f(n)| \\color{red} \\boldsymbol{ &lt; } \\color{black} c \\ g(n)\n∀c&gt;0,∃n0​&gt;0,∀n≥n0​:∣f(n)∣&lt;c g(n)\n注意:\n\n量词顺序是 ∀ ∃ ∀\\forall \\ \\exist \\ \\forall∀ ∃ ∀。\n因为是对于全部的 ccc 存在 n0n_0n0​，因此 n0n_0n0​ 的数值可以依赖于 ccc。\n与Big-Oh不同，最后的符号是 &lt;&lt;&lt; 而不是 ≤\\leq≤。\n\nlittle-oh也可以被定义为：\nlim⁡n→∞f(n)g(n)=0\\lim_{n \\to \\infty} \\frac{f(n)}{g(n)} = 0\nn→∞lim​g(n)f(n)​=0\n 性质\nlittle-oh作为一个二元关系(binary relation)，拥有以下性质：\n\nlittle-oh不具有自反性(Reflexive, e.g. xRxx R xxRx)。即f(n)=nf(n) = nf(n)=n 不是 o(n)o(n)o(n)。\nlittle-oh不具有对称性(Symmetric, e.g. xRy  ⟺  yRxx R y \\iff y R xxRy⟺yRx)。\nlittle-oh具有传递性(Transitive, e.g. xRy  &amp;  yRz→xRzx R y \\ \\ \\&amp; \\ \\ y R z \\to xRzxRy  &amp;  yRz→xRz)。\n\nlittle-oh 更像是严格的 &lt;&lt;&lt;。\n 特点\n\n与Big-Oh类似，little-Oh定义是函数的严格无法到达的上限。\nlittle-oh的意思是，当nnn足够大时，f(n)f(n)f(n)的增长速率小于g(n)g(n)g(n)。\nlittle-oh中 g(n)g(n)g(n) 阶级越小，越能说明 f(n)f(n)f(n) 的增长率。\n\n 推论 &amp; 方法\n\n推论1：如果f(n)f(n)f(n) 是 o(g(n))o(g(n))o(g(n))，那么 f(n)f(n)f(n) 一定是 O(g(n))O(g(n))O(g(n))\n正如 &lt; → ≤&lt;\\ \\to\\ \\leq&lt; → ≤ 一样，很明显 O(g(n))⊂o(g(n))O(g(n)) \\subset o(g(n))O(g(n))⊂o(g(n))。\n推论2 （乘法1）：如果f1(n)f_1(n)f1​(n) 是 o(g1(n))o(g_1(n))o(g1​(n)), f2(n)f_2(n)f2​(n) 是 o(g2(n))o(g_2(n))o(g2​(n))，那么 f1(n)f2(n)f_1(n)f_2(n)f1​(n)f2​(n) 是 o(g1(n)g2(n))o(g_1(n)g_2(n))o(g1​(n)g2​(n))。\n推论3 （乘法2）：如果f1(n)f_1(n)f1​(n) 是 o(g1(n))o(g_1(n))o(g1​(n)), f2(n)f_2(n)f2​(n) 是 O(g2(n))O(g_2(n))O(g2​(n))，那么 f1(n)f2(n)f_1(n)f_2(n)f1​(n)f2​(n) 是 o(g1(n)g2(n))o(g_1(n)g_2(n))o(g1​(n)g2​(n))。\n\n与Big-Oh类似，little-Oh也可以使用删除规则。与Big-Oh不同的是，little-Oh不能选择事实删除规则后的函数，而只能选择比该函数阶级更大的函数。\n 例子\n\n证明 f(n)=n2+nf(n) = n ^ 2 + nf(n)=n2+n 是 o(n3)o(n^3)o(n3)\n要证明f(n)=n2+nf(n) = n ^ 2 + nf(n)=n2+n 是 O(n3)O(n^3)O(n3)，则需要证明 ∀c&gt;0,∃n0&gt;0,∀n≥n0:f(n)&lt;c g(n)\\forall c &gt; 0, \\exist n_0 &gt; 0, \\forall n \\geq n_0 : f(n) &lt; c \\ g(n)∀c&gt;0,∃n0​&gt;0,∀n≥n0​:f(n)&lt;c g(n)。\n代入和整理可得 ∀c&gt;0,∃n0&gt;0,∀n≥n0:cn2−n−1&gt;0\\forall c &gt; 0, \\exist n_0 &gt; 0, \\forall n \\geq n_0 : cn^2-n-1 &gt; 0∀c&gt;0,∃n0​&gt;0,∀n≥n0​:cn2−n−1&gt;0。\n由公式可得，若 cn2−n−1=0cn^2-n-1 = 0cn2−n−1=0，且nr&gt;0n_r &gt; 0nr​&gt;0，可解得 nr=1+4c+12c&gt;0n_r = \\frac{1 + \\sqrt{4c + 1}}{2c} &gt; 0nr​=2c1+4c+1​​&gt;0。\n且当 n&gt;nrn &gt; n_rn&gt;nr​ 时，cn2−n−1&gt;0cn^2 - n - 1 &gt; 0cn2−n−1&gt;0 恒成立，那么可以取 n0=nr+1=1+4c+12c+1n_0 = n_r + 1 = \\frac{1 + \\sqrt{4c + 1}}{2c} + 1n0​=nr​+1=2c1+4c+1​​+1，使得 ∀n≥n0:f(n)&lt;c g(n)\\forall n \\geq n_0 : f(n) &lt; c \\ g(n)∀n≥n0​:f(n)&lt;c g(n) 恒成立。\n因此，f(n)=n2+nf(n) = n ^ 2 + nf(n)=n2+n 是 O(n3)O(n^3)O(n3)，此时对于所有的 ccc 取 n0=1+4c+12c+1n_0 = \\frac{1 + \\sqrt{4c + 1}}{2c} + 1n0​=2c1+4c+1​​+1。\n\n\n 关于Big-Oh和little-oh的定义上的思考：\n如果将Big-Oh的定义改为：∃c&gt;0,∃n0&gt;0,∀n≥n0:∣f(n)∣&lt;c g(n)\\exist c &gt; 0, \\exist n_0 &gt; 0, \\forall n \\geq n_0 : |f(n)| \\color{red} \\boldsymbol{ &lt; } \\color{black}c \\ g(n)∃c&gt;0,∃n0​&gt;0,∀n≥n0​:∣f(n)∣&lt;c g(n)，称为 O&lt;O_&lt;O&lt;​，而原定义称为 O≤O_{\\leq}O≤​，\n那么实际上，对于 g(n)&gt;0g(n) &gt; 0g(n)&gt;0， f(n)f(n)f(n) 是 O&lt;(g(n))  ⟺  f(n)O_&lt;(g(n)) \\iff f(n)O&lt;​(g(n))⟺f(n) 是 O≤(g(n))O_{\\leq}(g(n))O≤​(g(n))。\n唯一的区别是对于 f(n)=0,g(n)=0f(n) = 0, g(n) = 0f(n)=0,g(n)=0 来说 000 是 O≤(0)O_{\\leq}(0)O≤​(0) 而不是 O&lt;(0)O_&lt;(0)O&lt;​(0)。\n而我们想要定义Big-Oh的渐进符号为 ≤\\leq≤，就得要求 000 是 O(0)O(0)O(0)，因此使用 ≤\\leq≤ 而不是 &lt;&lt;&lt;。\n同理，对于little-oh如果定义改为：∀c&gt;0,∃n0&gt;0,∀n≥n0:∣f(n)∣≤c g(n)\\forall c &gt; 0, \\exist n_0 &gt; 0, \\forall n \\geq n_0 : |f(n)| \\color{red} \\boldsymbol{ \\leq } \\color{black}c \\ g(n)∀c&gt;0,∃n0​&gt;0,∀n≥n0​:∣f(n)∣≤c g(n)，称为 o≤o_{\\leq}o≤​，而原定义称为 o&lt;o_{&lt;}o&lt;​。\n此时 o&lt;o_{&lt;}o&lt;​ 与 o≤o_{\\leq}o≤​ 定义的唯一区别也是当 f(n)=0,g(n)=0f(n) = 0, g(n) = 0f(n)=0,g(n)=0 的时候，此时 000 是 o≤(0)o_{\\leq}(0)o≤​(0) 而不是 o&lt;(0)o_{&lt;}(0)o&lt;​(0)。\n而我们想要定义little-oh的渐进符号是 &lt;&lt;&lt;，就得要求 000 不是 o(0)o(0)o(0)，那么使用的是 &lt;&lt;&lt; 而不是 ≤\\leq≤。\n实际上，对于Big-Oh和little-oh最主要的区别是 ∃c\\exist c∃c 和 ∀c\\forall c∀c。\n\n 常用表示表[1]\n根据阶级(order)从小到大排名。\n\n\n\n表示\n中文名\n英文名\n数量级\n\n\n\n\nO(nc),c&lt;0O(n^c), c &lt; 0O(nc),c&lt;0 ororor O(kn)O(\\frac{k}{n})O(nk​)\n负数幂级\nnegative power\n∞\\infty∞,不存在\n\n\nO(1)O(1)O(1)\n常数级\nconstant\n∞\\infty∞\n\n\nO(log⁡log⁡n)O(\\log{\\log{n}})O(loglogn)\n双对数级\ndouble logarithmic\n221062^{2^{10^6}}22106\n\n\nO(log⁡n)O(\\log{n})O(logn)\n对数级\nlogarithmic\n1030103010^{301030}10301030\n\n\nO((log⁡n)c),c&gt;1O((\\log{n})^c), c &gt; 1O((logn)c),c&gt;1\n多重对数级\npolylogarithmic\n2106c2^{10^{\\frac{6}{c}}}210c6​\n\n\nO(nc),0&lt;c&lt;1O(n^c), 0 &lt; c &lt; 1O(nc),0&lt;c&lt;1 ororor O(nc)O(\\sqrt[c]{n})O(cn​)\n分数幂级\nfractional power\n106c10^{6c}106c\n\n\nO(n)O(n)O(n)\n线性级\nlinear\n10610^6106\n\n\nO(nlog⁡n)=O(log⁡n!)O(n\\log{n}) = O(\\log{n!})O(nlogn)=O(logn!)\n对数线性/拟线性级\nloglinear, n-log-n\n10510^5105\n\n\nO(n2)O(n^2)O(n2)\n二次级\nquadratic\n10310^3103\n\n\nO(nc),c&gt;1O(n^c), c &gt; 1O(nc),c&gt;1\n多项式/代数级\npolynomial, algebraic\n106c\\sqrt[c]{10^6}c106​\n\n\nO(cn)O(c^n)O(cn)\n指数级\nexponential\n6log⁡c106\\log_{c}{10}6logc​10\n\n\nO(n!)O(n!)O(n!)\n阶乘级\nfactorial\n999\n\n\n\n\n Big-Oh家族使用样例\n\n用于表示一个范围：算法 X 最坏的情况时间复杂度是 o(n4)o(n^4)o(n4) 和 Ω(n3)\\Omega(n^3)Ω(n3)，但是实际表现并不确定。\n用于确定一个增长率：算法 X 最佳的情况时间复杂度是 Θ(n2)\\Theta(n^2)Θ(n2)。\n用来表示一个平均值：算法 X 平均情况时间复杂度是 O(n3)O(n^3)O(n3)。\n\n\n 使用Big-Oh家族分析算法效率注意点\nBig-Oh家族之所以实用是因为它隐藏了低阶项和常数。它们主要分析当 nnn 足够大时渐进的范围,也可以说是 nnn 的增长率。\n但是在 nnn 比较小时这些被隐藏掉的项可能会成为非常重要的参考指标。也就是说不能完全根据Big-Oh家族和阶级大小来完全判断一个算法的实际工作时的效率。\n例如：\n\n10000n10000n10000n 是 O(n)O(n)O(n)，同时 2n2^n2n 是 O(2n)O(2^n)O(2n)，当时当 nnn 比较小时，例如 n=6n = 6n=6 时，前者需要进行的计算数是 600006000060000，而后者是 646464，此时前者的效率是不如后者的。\nO(1.02n)O(1.02^n)O(1.02n) 尽管是指数级(exponential)，但是它的效率并不逊色。\n\n但是Big-Oh家族在理论上对算法效率进行分析往往是有效的，并且在 nnn 比小的时候程序所消耗的时间往往是会忽略不计的。\n\n 总结\n\nBig-Oh家族定义及其渐进表示法总结[1:1]\n\n\n\n\n表示法\n名字\n描述\n渐进符号\n形式定义\n\n\n\n\no(g(n))o(g(n))o(g(n))\nlittle-Oh\n函数渐进地由ggg支配\n&lt;&lt;&lt;\n∀c&gt;0,∃n0&gt;0,∀n≥n0:∣f(n)∣&lt;c g(n)\\forall c &gt; 0, \\exist n_0 &gt; 0, \\forall n \\geq n_0 : | f(n) | &lt; c \\ g(n)∀c&gt;0,∃n0​&gt;0,∀n≥n0​:∣f(n)∣&lt;c g(n)\n\n\nO(g(n))O(g(n))O(g(n))\nBig-Oh\n函数以ggg为渐进边界\n≤\\leq≤\n∃c&gt;0,∃n0&gt;0,∀n≥n0:∣f(n)∣≤c g(n)\\exist c &gt; 0, \\exist n_0 &gt; 0, \\forall n \\geq n_0 : |f(n)| \\leq c\\ g(n)∃c&gt;0,∃n0​&gt;0,∀n≥n0​:∣f(n)∣≤c g(n)\n\n\nΘ(g(n))\\Theta(g(n))Θ(g(n))\nBig-Theta\n函数由ggg为渐进边界和下边界\n≈\\approx≈\n∃c′&gt;0,∃c′′&gt;0,∃n0&gt;0,∀n≥n0:c′g(n)≤f(n)≤c′′g(n)\\exist c&#x27;&gt;0,\\exist c&#x27;&#x27;&gt;0, \\exist n_0 &gt; 0, \\forall n \\geq n_0 : c&#x27;g(n) \\leq f(n) \\leq c&#x27;&#x27;g(n)∃c′&gt;0,∃c′′&gt;0,∃n0​&gt;0,∀n≥n0​:c′g(n)≤f(n)≤c′′g(n)\n\n\nΩ(g(n))\\Omega(g(n))Ω(g(n))\nBig-Omega\n函数由ggg为渐进下边界\n≥\\geq≥\n∃c&gt;0,∃n0&gt;0,∀n≥n0:f(n)≥c g(n)\\exist c&gt;0,\\exist n_0&gt;0,\\forall n \\geq n_0: f(n) \\geq c\\ g(n)∃c&gt;0,∃n0​&gt;0,∀n≥n0​:f(n)≥c g(n)\n\n\nω(g(n))\\omega(g(n))ω(g(n))\nlittle-omega\n函数渐进支配ggg\n&gt;&gt;&gt;\n∃c&gt;0,∀n0&gt;0,∃n≥n0:f(n)&gt;c g(n)\\exist c&gt;0,\\forall n_0 &gt; 0, \\exist n \\geq n_0 : f(n) &gt; c\\ g(n)∃c&gt;0,∀n0​&gt;0,∃n≥n0​:f(n)&gt;c g(n)\n\n\n\n\n如何求解一个算法的时间复杂度Big-Oh：\n\n建立算法函数的伪代码。\n求出该算法函数的原始运算数(number of primitive operator)和输入大小n的函数关系。\n根据该函数求出Big-Oh表示。\n\n\n\n\n 三. 🏫Master定理\n 分而治之(Divide and Conquer)\n分而治之是一个设计算法的思想，它通常能够高速地处理问题。\n分而治之的组成成分如下：\n\n分解 (Divide)：将输入分为两个或多个不相交的输入子集。\n递归 (Recur)：使用递归解决这些子集的子问题。\n组合 (Conquer)：将所有子集的解组合起来形成输入的解。\n\n\n 递归关系 Recurrence Relation\n定义：\n\n\n\n\n\n\n\n\n\nA recurrence relation is a recursively-defined function.\n递归关系(Recurrence Relation)是使用递归定义的函数。\n假设一个程序的运行时间是 T(n)T(n)T(n)，那么递归关系会在一系列小于n的值中来表达 T(n)T(n)T(n)。\n\n例子：归并排序(merge-sort)的递归关系及其时间复杂度的证明\n关于归并排序的具体算法请看下面 五. 算法 中 归并排序。\n假设归并排序的运行时间为 T(n)T(n)T(n)，那么\nT(n)=2 T(n2)+b+anT(1)=1\\begin{aligned}\nT(n) &amp; = 2\\ T(\\frac{n}{2}) + b + an \\\\T(1) &amp; = 1\n\\end{aligned}\nT(n)T(1)​=2 T(2n​)+b+an=1​\n\n2 T(n2)2\\ T(\\frac{n}{2})2 T(2n​) 表示数组分成了两个子数组，每个子数组的大小为 n2\\frac{n}{2}2n​。\nbbb 是分裂的花费。\nananan 是 merge 的花费。\n\n因此我们经过带入可以得到：\n\nT(2)=2 T(1)+b+2a=2+b+2aT(2) = 2\\ T(1) + b + 2a = 2 + b + 2aT(2)=2 T(1)+b+2a=2+b+2a\nT(4)=2 T(4)+b+4a=2(2+b+2a)+b+4a=4+3b+8aT(4) = 2\\ T(4) + b + 4a = 2 (2 + b + 2a) + b + 4a = 4 + 3b + 8aT(4)=2 T(4)+b+4a=2(2+b+2a)+b+4a=4+3b+8a\nT(8)=2 T(4)+b+8a=2(4+3b+8a)+b+8a=8+7b+24aT(8) = 2\\ T(4) + b + 8a = 2 (4 + 3b + 8a) + b + 8a = 8 + 7b + 24aT(8)=2 T(4)+b+8a=2(4+3b+8a)+b+8a=8+7b+24a\n\n由此我们猜测 T(2k)=2k+(2k−1)b+k 2ka,k∈NT(2^k) = 2^k + (2^k - 1)b + k\\ 2^ka, k\\in \\mathbb{N}T(2k)=2k+(2k−1)b+k 2ka,k∈N\n我们可以使用数学归纳法(induction)来验证：\n\n\n\n\n\n\n\n\n\nClaim: T(2k)=2k+(2k−1)b+k 2ka,k∈NT(2^k) = 2^k + (2^k - 1)b + k\\ 2^ka, k\\in \\mathbb{N}T(2k)=2k+(2k−1)b+k 2ka,k∈N\nBase case: k=0,T(1)=1+0∗b+0∗1∗a=1k = 0, T(1) = 1 + 0 * b + 0*1*a = 1k=0,T(1)=1+0∗b+0∗1∗a=1 is meet the claim。\nStep case: Assume that the claim is true at k, and we need to prove that T(k+1)T(k + 1)T(k+1) is true.\nT(2k+1)=2 T(2k)+b+2k+1a=2(2k+(2k−1)b+k 2ka)+b+2k+1a=2k+1+(2k+1−2)b+b+k 2k+1a+2k+1a=2k+1+(2k+1−1)b+(k+1) 2k+1a\\begin{aligned} \nT(2^{k+1}) &amp; = 2\\ T(2^k) + b + 2^{k+1}a \\\\\n &amp; = 2 (2^k + (2^k - 1)b + k\\ 2^ka) + b + 2^{k + 1}a \\\\\n &amp; = 2^{k+1} + (2^{k+1} - 2)b + b + k\\ 2^{k+1}a + 2^{k + 1}a \\\\\n &amp; = 2^{k+1} + (2^{k+1} - 1)b + (k + 1)\\ 2^{k+1}a\n\\end{aligned} T(2k+1)​=2 T(2k)+b+2k+1a=2(2k+(2k−1)b+k 2ka)+b+2k+1a=2k+1+(2k+1−2)b+b+k 2k+1a+2k+1a=2k+1+(2k+1−1)b+(k+1) 2k+1a​\nQ.E.D.Q.E.D.Q.E.D.\n我们假设 T′(n)=n+(n−1)b+anlog⁡(n),for n=2k,k∈NT&#x27;(n) = n + (n - 1)b + an\\log(n), \\text{for } n = 2^k, k\\in \\mathbb{N}T′(n)=n+(n−1)b+anlog(n),for n=2k,k∈N。\n我们可以证明出 T(n)T(n)T(n) 是 Θ(T′(n))\\Theta(T&#x27;(n))Θ(T′(n))。\n因此，T(n)T(n)T(n) 是 Θ(nlog⁡n)\\Theta(n\\log n)Θ(nlogn)。\n\n\n\n Master定理 (Master Theorem)\n考虑存在下面的递归关系：\nT(n)=a T(nb)+f(n)T(1)=1\\begin{aligned}\nT(n) &amp; = a\\ T(\\frac{n}{b}) + f(n) \\\\\nT(1) &amp; = 1\n\\end{aligned}\nT(n)T(1)​=a T(bn​)+f(n)=1​\n这是一个由分而治之设计的算法：分解成 aaa 个子集，每个子集的大小是 nb\\frac{n}{b}bn​，此外每个递归/循环有一些额外的操作 f(n)f(n)f(n)。\nMaster定理(Master Theorem)是一个根据 a,ba, ba,b 的数值以及对 f(n)f(n)f(n) 进行放缩来快速求出T(n)T(n)T(n)的Big-Oh家族的方法。\n下面就对 f(n),a,bf(n), a, bf(n),a,b 不同情况进行讨论。\n注意，本笔记中不形式证明Master定理，具体可以自行查阅。\n &gt; f(n)=0f(n) = 0f(n)=0 时\n此时 T(n)=aT(nb)T(n) = aT(\\frac{n}{b})T(n)=aT(bn​)，我们可以使用数学归纳法证明出 T(bk)=akT(b^k) = a^kT(bk)=ak。\n我们令n=bkn = b^kn=bk，根据数学公式我们可以推导出 ak=(bk)log⁡baa^k = (b^k)^{\\log_ba}ak=(bk)logb​a，因此我们可以得到\nT(n)=nlog⁡baT(n) = n^{\\log_ba}\nT(n)=nlogb​a\n因此我们可以知道 T(n)T(n)T(n) 是 Θ(nlog⁡ba)\\Theta(n^{\\log_ba})Θ(nlogb​a)。\n &gt; f(n)≠0f(n) \\neq 0f(n)=0 时\n此时可以分为三种情况：\n\n\n\nf(n)f(n)f(n) 的形式\nccc 与 log⁡ba\\log_balogb​a 的关系\nT(n)T(n)T(n)的Big-Theta\n描述\n\n\n\n\nf(n)f(n)f(n) 是 O(nc)O(n^c)O(nc)\nc&lt;log⁡bac &lt; \\log_bac&lt;logb​a\nΘ(nlog⁡ba)\\Theta(n^{\\log_ba})Θ(nlogb​a)\nf(n)f(n)f(n) 的 增长率非常小，此时忽略 f(n)f(n)f(n)\n\n\nf(n)f(n)f(n) 是 Θ(nc(log⁡n)k),k≥0\\Theta(n^c(\\log n)^k), k \\geq 0Θ(nc(logn)k),k≥0\nc=log⁡bac = \\log_bac=logb​a\nΘ(nc(log⁡n)k+1)\\Theta(n^c(\\log n)^{k+1})Θ(nc(logn)k+1)\nf(n)f(n)f(n) 的 增长率适中，此时混合使用a,b,f(n)a, b, f(n)a,b,f(n)\n\n\nf(n)f(n)f(n) 是 Ω(nc)\\Omega(n^c)Ω(nc), 并满足正则条件\nc&gt;logbac &gt; log_bac&gt;logb​a\nΘ(f(n))\\Theta(f(n))Θ(f(n))\nf(n)f(n)f(n) 的 增长率非常大，此时只考虑 f(n)f(n)f(n)\n\n\n\n情况三中需要满足正则条件(Regularity Condition)：\n∃k&lt;1:af(nb)≤kf(n)\\exist k &lt; 1 : a f(\\frac{n}{b}) \\leq k f(n)\n∃k&lt;1:af(bn​)≤kf(n)\n该条件保证了这个条件确保 f(n)f(n)f(n) 不会增长过快导致 T(n)T(n)T(n) 完全被非递归部分主导。\n注意f(n)f(n)f(n) 的形式以及ccc 与 log⁡ba\\log_balogb​a 的关系。\n\n情况一中可知，f(n)f(n)f(n)的渐进上边界都不如 nlog⁡ban^{\\log_ba}nlogb​a，那么f(n)f(n)f(n) 的增长率是可以被忽略的。\n情况二中可知，f(n)f(n)f(n)的增长率是与 nlog⁡ban^{\\log_ba}nlogb​a 持平的，因此应该要混合使用a,b,f(n)a, b, f(n)a,b,f(n)。\n情况三中可知，f(n)f(n)f(n)的渐进下边界都超过了 nlog⁡ban^{\\log_ba}nlogb​a，因此只考虑 f(n)f(n)f(n)。\n\n\n 四. 🔒数据结构\n 一些定义\n\n\n遍历(Traversals)：指访问(visit)一个数据结构的所有元素。\n\n每一个元素只访问一次。\n访问的顺序是系统的、有序的、有意义的。\n\n\n\n抽象数据类型(Abstract Data Types, ADTs)：是数据结构的抽象。\n\n组成成分：\n\n储存的数据类型。\n对数据的操作。\n与操作相关的错误条件。\n\n\n一般ADT的相关操作会使用Big-Oh来限制效率。\n\n\n\n具体数据类型(Concrete Data Types, CDTs)：是数据结构的实际。\n\nADT的实现是通过选择不同的CDT。\nCDT是数据隐藏的和封装的（面向对象）。\nCDT的选择影响运行时间和空间使用。\n\n\n\n面向对象编程(Object-oriented)的原因：\n\n区分规范(specification) 和 实施细节(implementation details)\n使用相同的ADT来探索不同的CDTs。\n无需更改ADT的代码来快速更改和提升CDTs。\n\n\n\n\n 单向链表(Singly Linked List) (CDT)\n 介绍\n\n\n\n\n\n\n\n\n\nA singly linked list is a concrete data structure consisting of a sequence of nodes. Each node stores an element and a pointer/reference to the next node.\n 成员\n\nNode 节点\n\nElement 元素\nnext 指向下一个节点的指针\n\n\nhead : Node* 头节点指针\ntail : Node* 尾节点指针 (可选)\n\n 功能性函数\n插入类函数：\n\nvoid insertHead(Object)：插入头结点\n\n时间复杂度：O(1)O(1)O(1)\n\n\nvoid insertTail(Object)：插入尾节点\n\n如果有记录尾节点，时间复杂度： O(1)O(1)O(1)\n如果没有记录尾节点，时间复杂度： O(n)O(n)O(n)\n\n\n\n删除类函数：\n\nvoid removeHead()：删除头节点\n\n时间复杂度：O(1)O(1)O(1)\n\n\nvoid removeTail(Object)：删除尾节点\n\n无论有没有记录尾节点，时间复杂度：O(n)O(n)O(n)\n\n因为要让尾节点的前一个节点的next指针指向NULL\n\n\n\n\n\n交换类函数：\n\nvoid swapElement(Node, Node)：交换元素而不交换节点的位置\n\n时间复杂度 O(1)O(1)O(1)\n\n\nvoid swapNode(Node, Node)：交换节点的位置（不常用）\n\n时间复杂度 O(n)O(n)O(n)\n\n因为要找到这两个Node的上一个Node来修改next。\n\n\n\n\n\n\n 双向链表(Doubly Linked List) (CDT)\n 介绍\n\n\n\n\n\n\n\n\n\nA doubly linked list provides a natural extension of a singly linked list.Each node stores an element and a pointer/reference to the next node and a pointer/reference to the previous node.\n 成员\n\nNode 节点\n\nelement 元素\nnext 指向下一个节点的指针\npre 指向上一个节点的指针\n\n\nhead : Node* | Node 头节点指针/节点\ntail : Node* | Node 尾节点指针/节点\n\n 功能性函数\n插入类函数：\n\nvoid insertHead(Object)：插入头结点\n\n时间复杂度：O(1)O(1)O(1)\n\n\nvoid insertTail(Object)：插入尾节点\n\n如果有记录尾节点，时间复杂度： O(1)O(1)O(1)\n如果没有记录尾节点，时间复杂度： O(n)O(n)O(n)\n\n\nvoid insertAfter(Node, Object)：插入到Node节点后面\n\n时间复杂度：O(1)O(1)O(1)\n\n\n\n删除类函数：\n\nvoid removeHead()：删除头节点\n\n时间复杂度：O(1)O(1)O(1)\n\n\nvoid removeTail(Object)：删除尾节点\n\n如果有记录尾节点，时间复杂度： O(1)O(1)O(1)\n如果没有记录尾节点，时间复杂度： O(n)O(n)O(n)\n\n\n\n交换类函数：\n\nvoid swapElement(Node, Node)：交换元素而不交换节点的位置（不常用）\n\n时间复杂度 O(1)O(1)O(1)\n\n\nvoid swapNode(Node, Node)：交换节点的位置（建议）\n\n时间复杂度 O(1)O(1)O(1)\n\n\n\n 补充\n\n有两种双向链表设计方式\n\n让head和tail指向实实在在的节点。如果链表为空，则head = NULL, tail = NULL。\n分配head和tail为新的节点，节点的元素为空。如果链表为空，则head.next == tail。\n\n\n\n 数据结构的思考\n相比于数组 Array，链表数据结构具有较快的插入和删除能力。但是，链表具有较差的查询能力，其查询能力的时间复杂度是 O(n)O(n)O(n)。\n一般具有较快的插入、删除和查询能力的数据结构都比较复杂，例如：\n\n跳表 (Skip List)：其三个操作的时间复杂度都是 O(log⁡n)O(\\log n)O(logn)。\n平衡树(Balanced Trees)：其三个操作的时间复杂度都是 O(log⁡n)O(\\log n)O(logn)。\n\n红黑树(Red-Black Tree)\nAVL树(AVL Tree)\n\n\n哈希表(Hash Table)：其三个操作的平均时间复杂度都是 O(1)O(1)O(1)，最差情况下时间复杂度是 O(n)O(n)O(n)。\n\n\n 向量(Vector) (ADT)\n 介绍\n向量(Vector)是一种抽象数据类型(ADT)。向量的主要目的是创建一个比数组(Array)更泛用的模型。\n其主要的特性是：\n\n一个元素在向量中的索引(index)被认为是前面元素的个数(number of elements prceding it)。\n\n为了不完全依赖于数组，因此我们不使用“索引(index)”概念，而使用“前面元素的个数”概念。\n例如对于一个向量 AAA 来说，A[2]A[2]A[2] 表示有 222 个元素在它的前面，分别是 A[0],A[1]A[0], A[1]A[0],A[1]。\n这个概念也可以被称为排名(rank)。\n\n\n与数组固定大小不同，向量一个自动调节大小的数据结构。\n\n 向量ADT主要操作(operator)/方法\n\nObject elemAtRank(int r)：返回 rank 为 r 的元素。\nObject replaceAtRank(int r, Object o)：替换掉 rank 为 r 的元素为 o，并返回原来的元素。\nvoid insertAtRank(int r, Object o)：在 rank 为 r 的位置插入新的元素 o。\nObject removeAtRank(int r)：删除 rank 为 r 位置的元素。\nint size()：返回向量大小。\nboolean isEmpty()：返回向量是否为空。\n\n 使用向量作为栈(Stack)\n栈(Stack)是一个先入后出(first in last out, FILO)的数据结构，其操作主要是：\n\nObject top()：返回栈顶。\n\n相当于 elemAtRank(size())。\n\n\nvoid push(Object o)：在最后的元素(栈顶)后面添加一个新的元素。\n\n相当于 insertAtRank(size(), Object o)。\n\n\nvoid pop()：删除最后的元素(栈顶)。\n\n相当于 removeAtRank(size())。\n\n\n\n 基于数组的向量(Array-based Vector) (CDT)\n是使用一个大小为N的数组V作为向量的CDT，并使用整型变量n记录向量的大小。\n &gt;操作/方法时间复杂度分析\n\nelemAtRank(r)：可以直接返回V[r]，因此其时间复杂度是 O(1)O(1)O(1)。\nreplaceAtRank(r, o)：时间复杂度是 O(1)O(1)O(1)。\ninsertAtRank(r, o)：需要对原来的元素进行右平移，在最坏的情况下(即 r=0r = 0r=0 )时间复杂度是 O(n)O(n)O(n)。\nremoveAtRank(r, o)：需要对原来的元素进行左平移，在最坏的情况下(即 r=0r = 0r=0 )时间复杂度是 O(n)O(n)O(n)。\nsize()：直接返回变量 n，因此时间复杂度是 O(1)O(1)O(1)。\nisEmpty()：直接返回 n == 0，因此时间复杂度是 O(1)O(1)O(1)。\npush(o)：不需要进行平移。\n\n如果不需要扩大数组时间复杂度是 O(1)O(1)O(1)。\n扩大数组需要平摊时间(amortized time)获取时间复杂度。具体可以看下面扩大数组中不同策略。\n\n\npop()：不需要进行平移，因此时间复杂度是 O(1)O(1)O(1)。\n\n平摊时间(amortized time)是从一组操作中每个操作平摊下来的时间。与平均时间(average time)不同，后者主要是针对一次操作的平均时间。\n &gt;扩大数组(Resize Array)\n在insertAtRank(r, o) 和 push(o) 操作中，如果数组已经满了，那么需要替换数组为更大的数组。\n替换数组需要复制原来的数据到新的数据中。假设当前数组的大小为 ccc，每次替换所使用的时间为 s2s_2s2​，那么这个过程需要的时间T(c)=s2cT(c) = s_2cT(c)=s2​c，即这个过程的时间复杂度是 O(c)O(c)O(c)。\n扩大数组的方法一共有两种：\n\n\n增量策略(incremental strategy)：使用固定的常数 c 来进行扩大数组。\n\n假设执行push的次数为 nnn，那么替换数组的次数一共为 k=floor(n/c)k = floor(n / c)k=floor(n/c) 次。\n假设T(n)T(n)T(n)是执行push nnn 次所需要的运行时间，s1s_1s1​是一次push所需要的时间，s2s_2s2​是一次替换数组所需要的时间。\n\ns1s_1s1​ 和 s2s_2s2​ 都是常数。\nT(n)=s1n+s2(c+2c+...+kc)=s1n+s2ck(k+1)2T(n) = s_1n + s_2(c + 2c + ... + kc) = s_1n + s_2c\\frac{k(k+1)}{2}T(n)=s1​n+s2​(c+2c+...+kc)=s1​n+s2​c2k(k+1)​，因此 T(n)T(n)T(n) 是 O(n2)O(n^2)O(n2)。\n\n\n平摊下来每次 push 操作的时间复杂度是 T(n)n\\frac{T(n)}{n}nT(n)​ 是 O(n)O(n)O(n)。这个是要比一般 push 操作所需要的时间复杂度 O(1)O(1)O(1) 是要差的。\n\n\n\n双倍策略(doubling strategy)：双倍数组的大小。\n\n假设执行push的次数为 nnn，那么替换数组的次数一共为 k=floor(log⁡n)k = floor(\\log n)k=floor(logn) 次。\n假设T(n)T(n)T(n)是执行push nnn 次所需要的运行时间，s1s_1s1​是一次push所需要的时间，s2s_2s2​是一次替换数组所需要的时间。\n\ns1s_1s1​ 和 s2s_2s2​ 都是常数。\nT(n)=s1n+s2(1+2+4+...+2k−1)=(s1+s2)n−s2T(n) = s_1n + s_2(1 + 2 + 4 + ... + 2^{k - 1}) = (s_1 + s_2)n - s_2T(n)=s1​n+s2​(1+2+4+...+2k−1)=(s1​+s2​)n−s2​，因此 T(n)T(n)T(n) 是 O(n)O(n)O(n)。\n\n\n平摊下来每次 push 操作的时间复杂度是 T(n)n\\frac{T(n)}{n}nT(n)​ 是 O(1)O(1)O(1)。\n\n\n\n\n 树(Tree) (ADT)\n 介绍\n树是一种抽象数据结构(ADT)。\n\n\n\n\n\n\n\n\n\nIn computer science, a tree is an abstract model of a hierarchical structure. A tree consists of nodes with a parent-child relation.\n 成员\n\nNode 节点\n\nelement  元素\nparent 父节点\nchildren[] 子节点\n\n\nroot : Node* 根节点：不具有父节点的节点。\ninternal : Node 内节点：具有至少一个子节点的节点。\nleaf / external : Node 叶节点/外节点：不具有子节点的节点。\nancestors : Node → Node[] 祖先节点：(递归定义) 一个节点其父节点和其父节点的祖先节点的数组/集合。\ndescendant : Node → Node[] 祖孙节点：(递归定义) 一个节点其所有子节点和所有子节点的祖孙节点的数组/集合。\ndepth : Node → Int 节点的深度：该节点的祖先节点的个数(不包括自己)。\n\n根节点的深度为0，根节点的子节点深度为1，以此类推。\n\n\nheight : Tree → Int 树的高度：最大的叶节点深度。或者说从根节点到叶节点最长的路径(不包括根节点)。\n\n只有根节点的树的深度为0。\n\n\n\n 树ADT主要操作/方法：\n &gt; 基础方法 (Generic)：\n\nint size()：返回树的大小。\nbool isEmpty()：返回树是否为空。\nIterator iterator()：返回树的遍历所有元素的迭代器。\nIterator positions()：返回树的以一定顺序遍历位置的迭代器。\n\n &gt; 接入方法 (Accessor)：\n\nNode root()：返回树的根节点。\nNode parent(Node)：返回节点的父节点。\nIterator children(Node)：返回节点的子节点迭代器。\n\n &gt; 查询方法 (Query)：\n\nbool isInternal(Node)：是否是内部节点。\nbool isExternal(Node)：是否是叶节点。\nbool isRoot(Node)：是否是根节点。\n\n 树的遍历 (Traversals)\n &gt; 前序遍历 Preorder Traversal\n先遍历父节点，再从左到右遍历其子节点。\n1234Algorithm preOrder(v)  visit(v)  for each child w of v    preorder(w)\n &gt; 后序遍历 Postorder Traversal\n先遍历子节点，再遍历父节点\n1234Algorithm postOrde(v)  for each child w of v    postOrder(w)  visit(v)\n\n 二叉树(Binary Tree) (ADT)\n 定义\n二叉树是一种抽象数据结构(ADT)。\n\n一般定义：\n\n\n\n\n\n\n\n\n\n\na tree whose each internal node has at most two children, and the children of a node are an ordered pair, though one might be “missing”.\n\n递归定义：\n\n\n\n\n\n\n\n\n\n\nA tree consisting of a single node, or a tree whose root has an  ordered pair of “children”, each  of which is missing (a null) or is  the root of a binary tree\n\n特点：\n\n每个节点最多有两个子节点\n节点之间是有序的，即左子节点和右子节点，尽管有一个是空节点。\n\n\n\n 性质\n &gt; 合适/完满二叉树 (proper/full binary tree)\n\n\n\n\n\n\n\n\n\nA binary tree is said to be “proper” (a.k.a. “full”) if every internal node has exactly 2 children.\n如果二叉树的所有内部节点都具有两个子节点，那么称这个二叉树是合适/完满二叉树。\n &gt; 完美二叉树 (perfect binary tree)\n\n\n\n\n\n\n\n\n\nA binary tree is perfect if it is proper and all leaves are at the same depth.\n如果一个满二叉树中所有的子节点都在同一个深度，那么称这个二叉树是完美二叉树。\n\n在深度 ddd 拥有的节点的个数为 2d2^d2d\n在深度 ddd 及其以下的深度总结点个数为 2(d+1)−12^{(d+1)}-12(d+1)−1\n高度为 hhh 的树总节点为 nnn，那么有 h=log⁡2(n+1)−1h = \\log_{2}(n+1) - 1h=log2​(n+1)−1，n=2(h+1)−1n = 2^{(h + 1)} - 1n=2(h+1)−1\n\n &gt; 完全二叉树 (complete binary tree)\n\n\n\n\n\n\n\n\n\n除了叶节点所处的深度以外，其他深度是一个完美二叉树，并且叶节点是靠右排序的二叉树是完全二叉树。\n 二叉树的遍历 (Traversals)\n除了树通用的前序遍历和后序遍历以外，还有一个中序遍历(Inorder Traversal)：\n先遍历左子节点，再遍历该节点，最后遍历子节点。\n123456Algorithm inOrder(v)  if hasLeft(v)    inOrder(v.left)  visit(v)  if hasRight(v)    inOrder(v.right)\n 二叉树的效率分析\n\n求树的高度：如果树的大小为 nnn，那么：\n\n对于完美二叉树来说，时间复杂度是 Θ(log⁡(n))\\Theta(\\log(n))Θ(log(n))。\n对于非完美二叉树来说，考虑到一条链，时间复杂度是 Ω(log⁡(n))\\Omega(\\log(n))Ω(log(n)) 和 O(n)O(n)O(n)。\n\n\n\n 基于数组的二叉树 (Array-Based Representation of Binary Tree) (CDT)\n它也可以被称为 树形数组(tree-as-array)。它是一种使用数组作为CDT实现二叉树ADT的方式。\n一般使用 int rank(Node) 来表示节点的数组索引。注意，它返回的是整型。\n\nrank(root) = 1：根节点的索引是 111。\nrank(parent(node)) = rank(node) &gt;&gt; 1：每个节点的父节点是该节点的索引除以 222。\nrank(left_child(node)) = rank(node) &lt;&lt; 1：每个节点的左节点是该节点的索引乘以 222。\nrank(right_child(node)) = rank(node) &lt;&lt; 1 + 1：每个节点的右节点是该节点的索引乘以 222 加 111。\n\n树形数组的优点：\n\n能够节省空间。因为不用储存相关的指针，而是使用计算代替。\n储存能够更紧凑，具有更好的内存局部性&quot;better memory locality&quot;。\n很好地解决缓存和内存层次结构的问题——当访问数组元素时，其他条目可以被拉入缓存，因此访问速度更快。\n\n\n 优先队列(Priority Queue) (ADT)\n 介绍\n优先队列是一个抽象数据结构(ADT)。优先队列是储存一组具有 (key, value) 的数据结构，并能够有效地返回和操作其中具有最小/最大 key 的元素。\n一般我们默认优先队列是最小优先队列(Min-Priority Queue)，也就是返回/操作拥有最小key的元素。\n 优先队列ADT主要操作/方法：\n\nvoid insert(k, v)：插入一组(k, v)的元素。\nElement removeMin()：删除并返回具有最小key的元素。\nElement min()：返回具有最小key的元素。\nint size()：返回元素个数。\nbool isEmpty()：优先队列返回是否为空。\n\n 基于二叉堆(Binary Heap)的优先队列 (CDT)\n本笔记中默认的二叉堆是 小根堆。\n\n\n\n\n\n\n\n\n\nA binary heap is a complete binary tree storing key-value pairs at its nodes.\n二叉堆是将 (key, value) 对储存在节点的完全二叉树。\n除了二叉堆以外，还有二项式堆(Binomial Heap)和斐波那契堆(Fibonacci Heap)。\n二叉堆具有以下的性质：\n\nHeap-Order：对于每一个除了根以外的节点，都有 key(v) &gt;= key(parent(v))。\n\n即子节点的值不会比父节点更小。\n那么堆顶，即二叉堆的根节点是所有节点中的最小值。\n\n\nComplete Binary Tree：是一个二叉树。因此如果一共有 nnn 个节点，则树的高度为 h=log⁡nh = \\log nh=logn。\n\n 堆的插入(insert)\n步骤如下：\n\n根据完全二叉树性质寻找插入点 ZZZ 作为叶节点。\n储存 keykeykey 值给点 ZZZ。\n恢复堆序属性(unheap操作)：将插入点 ZZZ 从下到上进行 冒泡，如果父节点的 key 值比 ZZZ 大，那么就交换两个节点的位置或元素，直到父节点的 key 值比 ZZZ 小或者已经到达根节点。\n\n关于 111，如果使用结构体模拟树的结构，那么时间复杂度可能会达到 O(n)O(n)O(n)。但是如果使用数组作为CDT模拟二叉树(具体可看上方二叉树中基于数组的二叉树，树形数组)，那么只需要在数组的末尾插入新的节点即可，此时的时间复杂度是 O(1)O(1)O(1)。\n关于 333，因为二叉树的高度是 h=log⁡nh = \\log nh=logn，因此 upheap 操作的时间复杂度是 O(log⁡n)O(\\log n)O(logn)。\n 堆的删除(remove / pop)\n堆的删除指的是删除堆顶。步骤如下：\n\n使用最后一个节点 www 代替根节点。\n删除 www 原节点。\n恢复堆属性(Downheap操作)：选择两个子节点中最小的子节点，如果该子节点的key值比 www 节点的小，那么就交换两个节点的位置或元素，直到所有子节点的 key 值比 www 大或者已经达到叶节点。\n\n\n 映射(Maps) (ADT)\n 介绍\n\n\n\n\n\n\n\n\n\nA map models a collection of (key, value) entries that is searchable by the key.\n性质：\n\n具有搜索、插入、删除元素的功能。\n具有相同 key 值的元素是不被允许的。\n\n 映射ADT主要操作/方法：\n\nValue get(Key k)：如果存在key相应的元素，则通过 key 获取相应的 value，否则返回 NULL。\nValue put(Key k, Value v)：插入 (key, value) 对。如果已经存在 key 在映射里则返回 NULL，否则返回 value值。\nValue remove(Key k)：如果存在key相应的元素，则通过 key 来删除并返回该元素的 value，否则返回 NULL。\nint size()：返回元素个数。\nbool isEmpty()：返回是否为空。\nIterator keys()：返回 key 的迭代器。\nIterator values()：返回 value 的迭代器。\nIteraotr entries()：返回 (key, value) 的迭代器。\n\n 基于简单链表的MAP (CDT)\n\nget(k)：遍历链表来寻找 key。时间复杂度是 O(n)O(n)O(n)。\nput(k, v)：遍历链表来寻找是否有重复的 key，如果没有则插入到链表中。时间复杂度是 O(n)O(n)O(n)。\nremove(k, v)：遍历链表来寻找 key。时间复杂度是 O(n)O(n)O(n)。\n\n因为链表的特性（具有较差的访问能力），因此无论是排序的链表还是未排序的链表（链表无法使用二分查找法），时间复杂度操作都是 O(n)O(n)O(n)。\n 基于哈希表的MAP (CDT)\n基本思想：将每个 key 转化成 index 放入一个较大的数组 Array 中。\n哈希表的特性：\n\n哈希值 (hash value)：由哈希函数得到的值被称为哈希值。\n哈希码 h1h_1h1​ (hash code)：是一个键值转一个整型的函数，即keys → integers。一些可能的方法：\n\n将 key 的内存地址作为哈希码。\n将 key 的 bit 值转化成整型作为哈希码。一般用于内存不大于整型的数据类型，例如byte, short, int, float。\n将 key 的 bit 值划分成相同长度的部分，对这些部分求和(忽略溢出)。适用于内存大于整型的数据类型，例如 double, long。\n多项式累积方法。\n\n\n压缩函数 h2h_2h2​ (Compression function)：是一个将整型压缩到一定范围的函数，即integers → [0, N-1]。一些可能的方法：\n\n除法(Division)：h2(x)=xmod  Nh_2(x) = x \\mod Nh2​(x)=xmodN。\n\nNNN 通常是一个素数。\n\n\n乘加除法(Multiply, Add and Divide (MAD))：h2(x)=(ax+b)mod  Nh_2(x) = (ax + b) \\mod Nh2​(x)=(ax+b)modN。\n\na,ba, ba,b 是非负整数。\namod  N≠0a \\mod N \\neq 0amodN=0，否则无论 xxx 为多少总会映射到 bbb。\n\n\n\n\n哈希函数 hhh (hash function)：是一个将对象(Object)映射到一个固定的范围 [0,N−1][0, N-1][0,N−1] 整型的函数。\n\n此时有 h(x)=h2(h1(x))h(x) = h_2(h_1(x))h(x)=h2​(h1​(x))。\n哈希函数的主要目的是使用明显随机的方式来将 keys 分散。\n分散的目的是为了减少冲突(Collision)。\n随机的目的是为了减少模式(Pattern)，从而减少冲突。\n\n\n冲突 (Collision)：当不同的元素获取到相同的索引时，会发生冲突。一些可能的解决方法：\n\n分离链(Separate Chaining)：让相同 index 的元素以链表的形式连接起来。\n二叉搜索树(Binary Search Tree)。\n开放地址(Open addressing)：让冲突的新元素放入到下一个可用的数组中。一些可能的方法：\n\n线性探索(Linear probing)：使用一个常数 ccc 来进行冲突元素的新元素寻址，即h(k)+ch(k) + ch(k)+c。\n\n一般使用循环数组作为哈希表。\n可能会导致未来新元素使用更长的时间来寻址。\n如果数组满了可能会导致死循环，因此要规定最多循环次数。\n如果中间有冲突的数组被删除，可能会导致后面冲突的数组查询失败。\n\n一个删除的解决方案是不断检测右边是否具有相同的哈希值，如果相同则将该数值重新插入。\nLazy deletion延迟删除：将被删除的数值标记为“删除”，只当用到它的时候再进行修复。当被查询到“删除”标记的点时直接跳过而不是停止。\n\n\n\n\n双哈希(Double Hashing)：使用一个额外的哈希函数 d(k)d(k)d(k) 来辅助寻找新元素。\n\n新的哈希值为 (h(k)+j d(k))mod  N,j∈[0,N−1](h(k) + j\\ d(k))\\mod N, j\\in[0, N-1](h(k)+j d(k))modN,j∈[0,N−1]，选择第一个空元素作为哈希值。一些可能的 h(k)h(k)h(k)：\n\nd(k)=q−(kmod  q)d(k) = q - (k \\mod q)d(k)=q−(kmodq)，其中 q&lt;Nq &lt; Nq&lt;N 且 qqq 是素数。\n\n\n对于线性探索来说，d(k)=1d(k) = 1d(k)=1。\nNNN 必须是素数，以探索所有的可能数组包。\n\n\n\n\n\n\n\n那么使用哈希表来实现Map主要的思路是：\n\n寻找哈希函数：将 (k,v)(k,v)(k,v) 储存在 i=h(k)i = h(k)i=h(k) 索引的数组中。\n处理冲突。\n\n 基于分离链(Separate Chaining)处理冲突的方法\n因为分离链定义让相同 index 的元素以链表的形式连接起来，其中链表中每个节点还有一个单独的 key 值用于寻找具体的元素。\n那么链表的每个节点应该具有以下的操作，假设有 mmm 个冲突的元素：\n\nElement get(k)：获取key = k的元素。其时间复杂度是 O(m)O(m)O(m)。\nElement put(k, v)：放入(k, v)对的元素，需要检测是否有相同 key 的元素，如果有则返回null。因此时间复杂度是 O(m)O(m)O(m)。\nElement remove(k)：删除key = k的元素。其时间复杂度是 O(m)O(m)O(m)。\n\n那么使用基于分离链哈希表的map具体实现方式如下：\n\nget(k)：return A[h(k)].get(k)。\nput(k, v)：return A[h(k)].put(k)。注意要让 size++。\nremove(k): return A[h(k)].remove(k)。注意要让 size--。\n\n对于每个操作，最佳访问时间是 O(1)O(1)O(1)，最差访问时间依然是 O(n)O(n)O(n)，即全部都有冲突。但是平均下来，其时间复杂度应该是 O(n/N)O(n / N)O(n/N)，其中 NNN 是哈希表数组的容量。\n 哈希函数的性能分析\n在最坏的情况下，搜索、插入和删除的时间复杂度都是 O(n)O(n)O(n)。\n一般用负载因子(load factor) α=n/N\\alpha = n / Nα=n/N 来表示哈希表的性能。\n哈希表各个操作的期望值基本上都是 O(1)O(1)O(1)。具体证明可自行查阅。\n\n 二叉搜索树(Binary Search Tree) (ADT)\n\n\n\n\n\n\n\n\n\nA binary search tree is a binary tree storing (key,value) entries at its internal nodes and satisfying the following “search tree” property。\n二叉搜索树是一个储存(key,value)值到节点的二叉树，并满足下面的性质：\n性质：\n\n对于任意一个内部节点 vvv，拥有左子节点 uuu 和 右子节点 www，满足 key(u) &lt;= key(v) &lt;= key(w)。\n对于任意一个节点 vvv，其左边子辈的值都比 vvv 小，右边子辈的值都比 vvv 大。\n换句话说，二叉搜索树的中序遍历(inorder traversal)返回的数组一定是根据key升序的。\n\n 二叉搜索树ADT主要操作/方法\n\nNode search(Key k)：返回key = k的节点，如果没有则返回null。\n\n实现：比较当前节点储存的key 与 k 相比较，如果等于则返回。如果k大则查找右节点，如果k小则查找左节点。如果不存在节点，则返回null。\n时间复杂度是 O(h)O(h)O(h)，其中 hhh 是树的高度。\n如果是平衡二叉树，则时间复杂度是 O(log⁡n)O(\\log n)O(logn)。\n\n\nvoid insert(Key k, Value v)：插入 (k, v) 对。\n\n实现：使用二分法找到要插入的位置，将其插入进去。\n时间复杂度是 O(h)O(h)O(h)，其中 hhh 是树的高度。\n\n\nNode remove(Key k)：删除 key = k 的节点。\n\n实现：使用二分查找找到要删除的节点删除，分为下面四个情况：\n\n没有找到该节点，此时返回 null。\n该节点是叶节点，此时删除该节点。\n节点具有一个子节点，将该子节点替换到原来的位置。\n节点具有两个子节点，此时根据树的中序遍历找到当前key的下一个key节点 www (www 称为该节点的中序后继)，并使用这个节点 www 替代该节点，再尝试删除 www，直到不符合被删除的节点具有两个子节点为止。\n\n\n时间复杂度是 O(h)O(h)O(h)，其中 hhh 是树的高度。\n\n\n\n 平衡二叉树(Balanced Trees)\n平衡二叉搜索树的任何结点的左子树和右子树高度最多相差1。\n平衡二叉树的高度 h=log⁡nh = \\log nh=logn。\n一般使用旋转(notation)的方法来让二叉搜索树逐步变成平衡二叉树。\n 一次旋转 (Single Rotation)\n过程如下：\n\n选择一个节点 PPP。\n选择该节点的一个子节点 CCC。\n交换两个节点：\n\n选择 CCC 中相反方向的子节点 VVV：如果 CCC 是 PPP 的左节点，那么就选择 CCC 的右节点。否则选择左节点。\n处理 PPP 的父节点：\n\n将 PPP 的父节点相应方向的子节点修改为 CCC。\n将 CCC 的父节点修改为 PPP 的父节点。\n如果 PPP 为根节点，那么修改根节点为 CCC。\n\n\n处理 CCC 的子节点 VVV：\n\n将 VVV 的父节点修改为 PPP。\n将 PPP 原来方向上的子节点 CCC 的位置修改为 VVV。\n\n\n处理 CCC 和 PPP：\n\n将 CCC 原来 VVV 位置的子节点修改为 PPP。\n将 PPP 的父节点修改为 CCC。\n\n\n\n\n\n\n整个过程时间复杂度是 O(1)O(1)O(1)。\n具体的其他二叉树方法将（例如AVL树、红黑树）不在本笔记中展示。可能会未来在其他笔记中展示。\n \n\n 五. 💻算法\n算法的设计思路通常有这么几种：\n\n暴力搜索(Brute Force)：生成所有潜在解决方案并测试哪些是实际解决方案。时间复杂通常非常高，是属于多项式级其以上的时间复杂度。\n分而治之(Divide and Conquer)：递归地将问题分解成更小的部分并逐步解决它们，然后将它们重新组合在一起。是一种比较高效的设计思路。\n启发式(Heuristics)：是一个使用经验法则(rule of thumb)设计的算法。启发式算法比简单的方法能够做出更好的决策，但仍然不一定是最佳的。\n动态规划(DP)：DP是一种适用于最优解满足“分解性质”情况的通用方法。\n\n\n 排序算法(Sorting algorithms)\n排序算法的性质：\n\n排序稳定性(Stability)：如果两个元素键值相等，排序算法会保留这两个元素的相对位置。\n排序自适应性(Adaptive)：如果数组已经接近已排序，那么算法的效率会提高。\n排序接入模式(Access Patterns)\n\nSequential Access：数据的读取和写入是按照其在存储器中存放的顺序进行的。\nRandom Access：数据储存中能够在常数时间 O(1)O(1)O(1) 内直接访问任意位置的数据。\n\n\n是否需要额外空间。\n\n如果没有特殊说明，以下算法都默认从小到大排序/升序、使用 数组(array) 作为数据结构。\n 基于比较的排序算法的一些思考\n如果一个排序算法仅包含关于成对比较元素的信息，那么就称这个排序是基于比较的(comparison-based)。\n并不是所有的排序算法都是基于比较的，例如桶排序(bucket sort)是使用实际的值来进行排序的，其时间复杂度是O(n)O(n)O(n)，但是其实现依赖于其值的范围。是一种使用空间换取时间的方法。\n对于 nnn 个数的数组来说，它一共拥有 n!n!n! 种排序方法。我们使用基于比较的算法来对数组进行排序是通过两两比较来减半它排序方法的可能性。也就是说，基于比较的排序算法本质其实是逐步将 n!n!n! 减半成 111。\n这意味着我们需要去做 log⁡2(n!)\\log_2(n!)log2​(n!) 次比较。实际上 O(log⁡(n!))=O(nlog⁡n)O(\\log(n!)) = O(n \\log n)O(log(n!))=O(nlogn)。也就是说基于比较的算法不能比 O(nlog⁡n)O(n \\log n)O(nlogn) 更优。\n\n 1. 冒泡排序(Bubble sort)\n 基本思想\n让大的元素逐渐往后移动。\n\n外部循环(Outer loop)：扫描整个数组。\n内部循环(Inner loop)：对于数组每个元素与右边邻域对比，如果右边邻域更小则立即交换。\n\n 算法思考\n因为算法中最大元素像水泡一样逐渐向上冒，因此被称为冒泡排序。\n 复杂性分析\n考虑到最差的情况，也就是每次循环都会进行交换。外部循环次数为(n−1)(n - 1)(n−1)，假设当前外部循环index=iindex = iindex=i，那么内部循环次数为 (n−i−1)(n - i - 1)(n−i−1)，因此总循环次数为 n(n−1)2\\frac{n(n - 1)}{2}2n(n−1)​。\n假设比较和交换原始操作数为 ttt 为常数，循环以外的原始操作数为 kkk 为常数，那么总原始操作数为 n(n−1)2+t(n−1)+k\\frac{n(n - 1)}{2} + t(n - 1) + k2n(n−1)​+t(n−1)+k。\n根据删除规则，我们可以知道它的时间复杂度是 O(n2)O(n^2)O(n2)。\n此外，也可以使用递归关系来证明冒泡排序的时间复杂度：\n\n使用递归关系证明冒泡排序的时间复杂度\n首先冒泡排序并不是天然递归的，而是一个双重循环。\n但是我们能使用递归思想来将冒泡排序改成递归：如果要将长度为 nnn 的数组进行排序，首先将这个数组中的最大数值通过冒泡操作交换到当前数组最右边的位置并固定，随后再将剩下 n−1n - 1n−1 的数组进行排序(递归)。\n这样就写出其运行时间的递推公式：\nT(n)=dn+T(n−1)T(1)=1\\begin{aligned} \nT(n) &amp; = dn + T(n - 1) \\\\\nT(1) &amp; = 1\n\\end{aligned}\nT(n)T(1)​=dn+T(n−1)=1​\n\ndndndn 表示通过冒泡操作交换所需要的时间。\nT(n−1)T(n - 1)T(n−1) 表示剩余数组排序所需要的时间。\n\n我们可以根据等差数列求出 T(n)T(n)T(n) 的通项公式为：\nT(n)=1+(n(n+1)2−1)dT(n) = 1 + (\\frac{n(n+1)}{2} - 1) d\nT(n)=1+(2n(n+1)​−1)d\n那么很明显 T(n)T(n)T(n) 是 Θ(n2)\\Theta(n^2)Θ(n2)。\n\n\n 算法的性质。\n\n如果相同的元素不进行交换，那么该算法 具有 稳定性。\n可以通过添加变量来让算法 具有 自适应性（内部循环没有进行任何交换）。\n不需要额外的空间。\n可适用于单向链表的swapElement(Node, Node)，时间复杂度不变。\n\n\n 2. 选择排序(Selection sort)\n 基本思想\n保持数组后面的元素不变作为已排序的元素，前面的元素作为未排序的元素，选择未排序的元素组中最大的元素插入到已排序元素组的头部。\n\n外部循环：扫描整个数组。\n内部循环：扫描整个未排序部分的数组。并不会让最大的元素立即交换，而是记录住最大元素的位置。等内部循环扫描完，将被记录的元素：\n\n插入到已排序部分的数组的最左边。或者：\n与未排序部分的数组最右边的元素交换并将其加入到已排序部分数组。\n\n\n\n 算法思考\n与冒泡排序不同，冒泡排序是比较当前元素和其邻域，而该排序是比较当前元素和被记录的元素。\n为什么要延迟交换而不是立即交换：\n\n如果交换操作可能会比较昂贵，并不像数组一样是O(1)O(1)O(1)，那么就需要尽可能减少交换次数。\n如果数组非常大，那么需要尽可能地减少交换次数来提高效率。\n\n 复杂度分析\n相比于冒泡排序，它们具有相同数量的迭代和比较，仅仅是有更少数量的交换。\n因此它的时间复杂度也是O(n2)O(n^2)O(n2)。\n 算法的性质。\n\n该算法 不具有 稳定性。\n该算法 不具有 自适应性。\n不需要额外的空间。\n可适用于单向链表的swapElement(Node, Node)，时间复杂度不变。\n\n\n 3. 插入排序(Insertion sort)\n保持数组前面元素的排序不变作为已经排序的元素，后面的元素作为未排序的元素。选择当前未排序元素不断交换左边比该元素大的元素，并将其加入到已经排序的元素。\n\n外部循环：扫描整个数组。\n内部循环：获取并记录当前未排序元素的最左边元素，从右到左扫描已经排序的元素，如果被扫描的元素比记录的元素大，那么就交换，直到被扫描的元素比记录的元素小。\n\n 复杂度分析\n\n在最坏的情况下，它的外部原始操作数是 O(n)O(n)O(n)，内部原始操作数是 O(n)O(n)O(n)，因此它的总时间复杂度是O(n∗n)=O(n2)O(n * n) = O(n^2)O(n∗n)=O(n2)。\n在最佳的情况下，它内部循环操作数是 O(1)O(1)O(1)，那么它的总时间复杂程度是 O(n∗1)=O(n)O(n * 1) = O(n)O(n∗1)=O(n)。\n\n 算法的性质\n\n如果相同的元素不进行交换，那么该算法 具有 稳定性。\n该算法 具有 自适应性。\n不需要额外的空间。\n不适用于单向链表。适用于双向链表。\n\n\n 4. 归并排序(Merge sort)\n归并排序是一个基于分而治之(divide-and-conquer)的算法，它是先划分再排序。\n\n分解 (Divide)：将待排序的数组 SSS 分解为两个部分 S1S_1S1​, S2S_2S2​。\n\n分解直到只剩下单个元素或者空元素为止。因为单个元素的数组一定是已经排序好的数组。\n分解只是简单的数学运算，因此时间复杂度是 O(1)O(1)O(1)。\n\n\n递归 (Recur)：递归地将 S1S_1S1​ 和 S2S_2S2​ 进行排序(带入到分而治之中)。\n\n递归分解，回归组合。\n递归全部子集的时间复杂度是 O(log⁡(n))O(\\log(n))O(log(n))。\n\n\n组合 (Conquer)：将已排序的 S1S_1S1​ 和 S2S_2S2​ 合并(merge)。\n\nmerge是基于两个已经排序好的数组进行的：依次判断两个数组当前第一个数(最小的数)，选择最小的一个放入到新的数组后面，直到有一个数组为空后，将另一个数组剩余的元素依次放入到新的数组后面。\n假设放入的操作时间复杂度是O(1)O(1)O(1)，那么合并的时间复杂度是 O(n)O(n)O(n)。\n\n\n\n归并排序递归调用的过程是一个二叉树结构。\n\n 复杂度分析\n综上所述，归并排序的时间复杂度是 O(nlog⁡n)O(n\\log{n})O(nlogn)。\n此外可以使用递归关系来证明归并排序的时间复杂度，详细请见 三.Master定理 中 递归关系 中的样例。\n归并排序需要用到额外的空间，因此其空间复杂度是 O(n)O(n)O(n)。\n也可以使得空间复杂度是 O(1)O(1)O(1)，但是过于混乱一般不作考虑。\n 算法的性质\n\n在归并遇见相等数据时，如果优先选择左边数组那么该算法 具有 稳定性。\n该算法 不具有 自适应性。\n该算法 需要 额外的空间。\n该算法对数据的访问是顺序的(sequential)，因此在硬盘中具有较好的排序效率。\n因为依赖于快速对中间的数据进行访问，因此不太适合使用链表。\n\n\n 5. 快速排序(Quick Sort)\n快排是一个基于分而治之的算法，它是先排序后划分。\n\n分解 (Divide)：称之为partition操作。选择一个元素 xxx 称之为枢(pivot)，并将数组 SSS 分为：\n\nLLL：元素小于 xxx 的。\nGEGEGE 元素大于等于 xxx 的。\npivot经常是使用随机选择。\n假设 交换 或者 删除再插入 的时间复杂度是O(1)O(1)O(1)，那么分解的时间复杂度是 O(n)O(n)O(n)。\n\n\n递归 (Recur)：对 LLL 和 GEGEGE 使用进行递归排序，带入到分而治之中。\n\n最差的情况下，选择的枢总是最小/最大值，那么此时递归所有的子集时间复杂度是 O(n)O(n)O(n)。\n最佳的情况下，选择的枢总是中间值，那么此时递归所有的子集时间复杂度是 O(log⁡n)O(\\log n)O(logn)。\n\n\n组合 (Conquer)：将 LLL 和 GEGEGE 左右连接起来。\n\n组合只是简单的连接，时间复杂度是 O(1)O(1)O(1)。\n\n\n\n快速排序递归调用的过程是一个二叉树结构。\n 快速算法的分解(Divide)实现形式\n该操作称为partition操作。\n\n\n使用额外的空间进行分解，具体思想如下：\n\n创建两个数组，分别表示 LLL 和 GEGEGE。\n选择一个枢(pivot)。\n从左到右遍历数组，将小于枢的数加入到 LLL，将大于等于枢的数加入到 GEGEGE。\n\n\n\n使用双指针的方法进行分解，这个方法是就地(in-place)，步骤如下：\n\n选择一个枢(pivot)。\n定义两个指针 jjj 和 kkk，分别初始化指向数组的开头和结尾。\n使用 jjj 向右扫描，直到找到第一个 ≥\\geq≥ 枢的元素 或者 j==kj == kj==k 停止。\n使用 kkk 向左扫描，直到找到第一个 &lt;&lt;&lt; 枢的元素 或者 j==kj == kj==k 停止。\n交换 j,kj, kj,k 的元素。\n如果 j&lt;kj &lt; kj&lt;k，则返回 333。\n此时 j==kj == kj==k，并且此时 j,kj, kj,k 的位置元素等于枢，也是 GEGEGE 位置的左边界线。\n\n\n\n 算法的思考\n如果选择枢的方式是固定而不是随机的(例如总是选择第一个值作为枢)，并且出现了 LLL 子集是空的情况(此时选择的枢是最小值)，那么此时会导致算法出现死循环。因为每次对 GEGEGE 子集进行排序时，总是会选择最左边的值(也是最小值)作为枢，从而导致 LLL 子集是空的情况。\n\n\n\n\n\n\n\n\n\n快速排序要避免固定选择枢和出现一方子集是空集的情况，否则可能会导致死循环。\n\n解决方法1：使用随机的方式选择枢。\n解决方法2：将排序分为三个部分，分别是 LLL, {pivot}\\{pivot\\}{pivot}, E+GE+GE+G。\n解决方法3：三点取值，选择最左边的数、中间的数和最右边的数中的中位数作为枢。\n\n 复杂度分析\n\n最差的情况下，快速排序的时间复杂度是 O(n2)O(n^2)O(n2)。\n最佳的情况下，快速排序的时间复杂度是 O(nlog⁡n)O(n\\log{n})O(nlogn)。\n平均情况下，在一半的时间中快速排序选择的枢是中间值，那么时间复杂度是 O(nlog⁡n)O(n\\log{n})O(nlogn)。\n\n也可以认为平均情况下，选择的枢值总是让两个子集分解成 13\\frac{1}{3}31​ 和 23\\frac{2}{3}32​ 两个区域，也就是说递归二叉树的高度是 32log⁡n\\frac{3}{2}\\log n23​logn。\n具体证明可以自行查看维基百科。\n\n\n\n快速排序不需要用到额外的空间，因此其空间复杂度是 O(1)O(1)O(1)。\n 算法的性质\n\n快速排序 不具有 稳定性。\n该算法 不具有 自适应性。\n该算法 不需要 额外的空间，是就地(in-place)的算法。\n该算法对数据的访问是随机的(randomized)。\n因为是使用 交换 或者 删除再插入 操作进行，因此可以使用双向链表。\n\n\n 启发式算法(Heuristics)\n启发式算法是一个使用经验法则(rule of thumb)设计的算法。启发式算法比简单的方法能够做出更好的决策，但仍然不一定是最佳的。\n通常有两种：\n\n程序中的决策可以给出准确/最佳的答案，但通常是为了加快程序运行速度。\n\n例如，A*搜索算法中使用可接受的启发式方法(Admissible heuristic)、在快速排序算法中使用随机选择的方式选择枢(pivot)。\n\n\n程序中的决策可能不会给出最佳答案，但旨在给出以其他方式无法获得的良好答案。\n\n一般用于解决一些NP-hard问题，例如 TSP问题、图染色问题等。\n例如 遗传算法、模拟退火。\n具体可以参考AIM-优化算法笔记。\n\n\n\n 贪心算法(Greedy)\n贪心算法是一种常见的启发式算法。贪心算法是做出短期内看起来最好的决定，而不考虑未来的策略。\n一些贪心算法可以得到最优解，例如最小生成树(Minimal Spanning Tree, MST)中Prim算法。\n大部分贪心算法无法给出最优解，但是可以给出接近最优的解。\n 最小生成树问题(Minimal Spanning Tre, MST)\n问题输入：联通的、有边权值的无向图(connected, undirected, weighted graph)。\n问题输出：一棵树，仅使用图中存在的边连接图中所有顶点，并且边权重的和是最小的。\n Prim算法\n思路：\n\n选择任意顶点 MMM。\n选择对外可以连接到的所有的点中最小的那个边，并将边加入到 MST中，将点加入到内部的点中。\n是否全部连接，如果没有则返回 222。通过已连接的边个数判断，即 边的个数 e=n−1e = n - 1e=n−1。\n\n算法实现：\n\n1.1.1. 初始化数组 value[n] = inf，数组大小为点的个数，表示表示内部点对未连接的点边权的最小值；初始化连接边的个数m = 0。\n2.2.2. 随机选择一个点 MMM。\n3.3.3. 使value[M] = 0，并根据 MMM 连接的所有边 (M,V)(M, V)(M,V) 更新 edge 数组。即\n\n12345value[M] = 0              # 因为已经被连接，所以更新为0forall e in edge(M)  v = e.v                 # 获取边连接的另一个点  if(e.value &lt; value[v])  # 根据边权值更新对外连接点的大小    value[v] = e.value \n\n4.4.4. 找到 value[v] != 0 中最小的点 VVV，使 value[V] = 0，m++。\n5.5.5. 跟 333 一样根据 VVV 连接的所有边 (V,U)(V, U)(V,U) 更新 edge 数组。\n6.6.6. 判断是否所有的点已经连通，即 (m - 1) == n，如果没有则返回 444。\n\n\n 动态规划(Dynamic Programming, DP)\n\n\n\n\n\n\n\n\n\nDP is a general method that can be suitable when the optimal solutions satisfy a “decomposition property”.\nDP 是一种适用于最优解满足“分解性质”情况的通用方法。\nDP的步骤通常如下：\n\n将最优解分解为子解相当于将问题分解为子问题，并且子解对于子问题是最优的。\n因此，最优解可以通过更小的子问题的最优解来构建。\n\n与分治法不同的是，DP中的子问题可以重叠，即不同的路径可能会遇见相同的子问题。\n因此DP的思想通常是，对于某一个解 SnS_nSn​，如果我想要得到这个解，我该直到哪些解才能得出这个解，并依次获取和尝试合并这些可能解的组合。又或者说，我现在已知某一个解，我是否可以让这个解和其他输入/解组合获取一个新的解。其中这个“得到”和“获取”的过程是一个状态转移的过程，这个过程是一个状态转移方程/贝尔曼方程(Bellman Equation)。\n\n例如，假设有这样一个问题：给出一个整型集合 SSS，和一个目标值 KKK，我是否可以找出一个 SsubS_{sub}Ssub​ 的子集，其元素的和等于 KKK。\n\n假设我们输入 S[i],0≤i≤(n−1)S[i], 0 \\leq i \\leq (n-1)S[i],0≤i≤(n−1) 是集合第 iii 个元素。\n我们使用 dp[i][m]=true,0≤m≤Kdp[i][m] = true, 0 \\leq m \\leq Kdp[i][m]=true,0≤m≤K 来表示使用前 iii 个元素组成的子集中 SsubS_{sub}Ssub​ 元素和可以等于 mmm。\n如果我们知道 dp[i−1][m]=truedp[i - 1][m] = truedp[i−1][m]=true，那么可以根据它和当前元素 S[i]S[i]S[i] 得出 dp[i][m+S[i]]=truedp[i][m + S[i]] = truedp[i][m+S[i]]=true。\n如何知道dp[i−1][m]=truedp[i - 1][m] = truedp[i−1][m]=true? 只需要对 mmm 进行遍历 (0≤m≤K−S[i])(0 \\leq m \\leq K-S[i])(0≤m≤K−S[i]) 依次检查是否为true即可。\n由此我们就可以得到状态转移方程：dp[i][m]=dp[i][m]  |  dp[i−1][m−S[i]]dp[i][m] = dp[i][m]\\ \\text{ | } \\ dp[i - 1][m - S[i]]dp[i][m]=dp[i][m]  |  dp[i−1][m−S[i]]。\n时间复杂度是 O(kn)O(kn)O(kn)。\n此外我们可以使用滚动数组将其变成一维dp，此时对容量 mmm 的遍历是倒着的（如果正着就会导致元素 iii 被重复计算，此时属于完全背包问题）。\n\n\n\n与暴力搜索，暴力搜索是将所有可能的答案依次列出来并测试，答案之间可能没有太大的关系。而动态规划是根据状态转移来尝试获取哪些解。\n\n 📘Reference\n\n\n\n源自: https://en.wikipedia.org/wiki/Big_O_notation ↩︎ ↩︎\n\n\n\n","slug":"笔记/笔记-ADE-算法数据结构和效率","date":"2024-05-24T17:42:20.000Z","categories_index":"笔记","tags_index":"Notes,Algorithm,Data Structure,Big-Oh","author_index":"zExNocs"},{"id":"d681443dee58dcfb94dec12db90a9a0d","title":"随笔日记导航","content":" 随笔\n 娱乐类随笔\n\n梗图\n记录网友怪话\n\n 技术类随笔\n\n让Hexo支持KaTeX和emoji\n\n\n 日记\n","slug":"导航/导航-随笔日记导航","date":"2024-05-24T17:15:32.000Z","categories_index":"导航","tags_index":"Diary,Essay","author_index":"zExNocs"},{"id":"c9fd788a84f48b02fed840451084249f","title":"笔记导航","content":" 按照年份分类\n Y3\n\nADE - 算法数据结构和效率 : 有关算法效率分析的课题笔记，包括Big-Oh家族、Master定理和部分算法与数据结构的算法分析。\n\n","slug":"导航/导航-笔记导航","date":"2024-05-24T14:25:57.000Z","categories_index":"导航","tags_index":"Notes","author_index":"zExNocs"},{"id":"625e3e920d4d18f0b54366f772b38b35","title":"语言学习导航","content":"","slug":"导航/导航-语言学习导航","date":"2024-05-24T10:44:53.000Z","categories_index":"导航","tags_index":"Languaue","author_index":"zExNocs"},{"id":"f2a68e25ffce8d6b8f475f30117ea7f4","title":"算法和数据结构导航","content":" 算法\n 数据结构\n","slug":"导航/导航-算法和数据结构导航","date":"2024-05-24T10:43:22.000Z","categories_index":"导航","tags_index":"Algorithm,Data Structure","author_index":"zExNocs"}]